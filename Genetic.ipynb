{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "data = np.loadtxt('train_data.txt')\n",
        "X = data[:, 0].reshape(-1, 1)  # Input features\n",
        "y = data[:, 1].reshape(-1, 1)  # Target values\n",
        "print(\"Dataset loaded successfully!\\n\")\n",
        "\n",
        "# Define possible activation functions\n",
        "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
        "\n",
        "# Custom callback to print loss at each epoch\n",
        "class PrintLoss(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {logs['loss']}\")\n",
        "\n",
        "# Create a random architecture with max_layers and max_neurons as limits\n",
        "def create_architecture(max_layers=3, max_neurons=100):\n",
        "    num_hidden_layers = random.randint(1, max_layers)  ",
        "    neurons_per_layer = [random.randint(1, max_neurons) for _ in range(num_hidden_layers)]\n",
        "    activation_functions_per_layer = [random.choice(activation_functions) for _ in range(num_hidden_layers)]\n",
        "\n",
        "    architecture = {\n",
        "        'num_hidden_layers': num_hidden_layers,\n",
        "        'neurons_per_layer': neurons_per_layer,\n",
        "        'activation_functions': activation_functions_per_layer,\n",
        "        'output_activation': random.choice(activation_functions)\n",
        "    }\n",
        "\n",
        "    print(\"Created architecture:\", architecture)\n",
        "    return architecture\n",
        "\n",
        "\n",
        "\n",
        "# Generate an initial population of architectures with max layers and neurons\n",
        "def create_population(size, max_layers=3, max_neurons=100):\n",
        "    print(f\"\\nGenerating initial population of size {size} with max layers={max_layers} and max neurons={max_neurons}...\")\n",
        "    population = [create_architecture(max_layers=max_layers, max_neurons=max_neurons) for _ in range(size)]\n",
        "    print(\"Initial population generated.\\n\")\n",
        "    return population\n",
        "\n",
        "# Create model based on architecture with output activation selection\n",
        "def create_model(architecture):\n",
        "    print(\"Creating model with architecture:\", architecture)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(architecture['neurons_per_layer'][0], input_dim=1, activation=architecture['activation_functions'][0]))\n",
        "    for i in range(1, architecture['num_hidden_layers']):\n",
        "        model.add(Dense(architecture['neurons_per_layer'][i], activation=architecture['activation_functions'][i]))\n",
        "    model.add(Dense(1, activation=architecture['output_activation']))\n",
        "    model.compile(optimizer=Adam(), loss='mse')\n",
        "    print(\"Model created and compiled successfully.\")\n",
        "    model.summary()  # Display model summary\n",
        "    return model\n",
        "\n",
        "# Define fitness function\n",
        "def fitness(architecture):\n",
        "    print(\"\\nEvaluating fitness for architecture:\", architecture)\n",
        "    model = create_model(architecture)\n",
        "    model.fit(X, y, epochs=50, verbose=0, callbacks=[PrintLoss()])\n",
        "    mse = model.evaluate(X, y, verbose=0)\n",
        "    print(\"Fitness (MSE) for this architecture:\", mse)\n",
        "    print(\"###############################################################\")\n",
        "    return mse\n",
        "\n",
        "# Selection based on fitness\n",
        "def select_population(population, fitness_scores, num_parents):\n",
        "    print(\"\\nSelecting parents based on fitness scores...\")\n",
        "    parents = sorted(zip(population, fitness_scores), key=lambda x: x[1])[:num_parents]\n",
        "    print(\"Selected parents:\", [p[0] for p in parents])\n",
        "    return [p[0] for p in parents]\n",
        "\n",
        "# Crossover\n",
        "def crossover(parent1, parent2):\n",
        "    print(\"\\nPerforming crossover...\")\n",
        "    child = create_architecture()\n",
        "    child['num_hidden_layers'] = random.choice([parent1['num_hidden_layers'], parent2['num_hidden_layers']])\n",
        "    child['neurons_per_layer'] = [random.choice([p1, p2]) for p1, p2 in zip(parent1['neurons_per_layer'], parent2['neurons_per_layer'])]\n",
        "    child['activation_functions'] = [random.choice([p1, p2]) for p1, p2 in zip(parent1['activation_functions'], parent2['activation_functions'])]\n",
        "    child['output_activation'] = random.choice([parent1['output_activation'], parent2['output_activation']])\n",
        "    print(\"Created child architecture after crossover:\", child)\n",
        "    return child\n",
        "\n",
        "def mutate(architecture, mutation_rate=0.1):\n",
        "    while len(architecture['neurons_per_layer']) < architecture['num_hidden_layers']:\n",
        "        architecture['neurons_per_layer'].append(random.randint(1, 100))\n",
        "    while len(architecture['activation_functions']) < architecture['num_hidden_layers']:\n",
        "        architecture['activation_functions'].append(random.choice(activation_functions))\n",
        "\n",
        "    for i in range(architecture['num_hidden_layers']):\n",
        "        if random.random() < mutation_rate:\n",
        "            architecture['neurons_per_layer'][i] = random.randint(1, 100)\n",
        "        if random.random() < mutation_rate:\n",
        "            architecture['activation_functions'][i] = random.choice(activation_functions)\n",
        "\n",
        "    if random.random() < mutation_rate:\n",
        "        architecture['output_activation'] = random.choice(activation_functions)\n",
        "\n",
        "    return architecture\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Genetic algorithm main loop\n",
        "def genetic_algorithm(population_size, generations, max_layers=3, max_neurons=100):\n",
        "    print(f\"\\nStarting Genetic Algorithm with population size {population_size} and {generations} generations...\\n\")\n",
        "    population = create_population(population_size, max_layers=max_layers, max_neurons=max_neurons)\n",
        "    best_mse = float('inf')\n",
        "    best_architecture = None\n",
        "    for generation in range(generations):\n",
        "        print(f\"Generation {generation + 1}/{generations}\")\n",
        "        fitness_scores = [fitness(ind) for ind in population]\n",
        "        parents = select_population(population, fitness_scores, population_size // 2)\n",
        "        next_population = []\n",
        "        while len(next_population) < population_size:\n",
        "            parent1, parent2 = random.sample(parents, 2)\n",
        "            child = crossover(parent1, parent2)\n",
        "            child = mutate(child)\n",
        "            next_population.append(child)\n",
        "        population = next_population\n",
        "        print(f\"Completed generation {generation + 1}\\n\" + \"-\"*80)\n",
        "\n",
        "        for ind, score in zip(population, fitness_scores):\n",
        "          if score < best_mse:\n",
        "              best_mse = score\n",
        "              best_architecture = ind  # Store the architecture, not the model\n",
        "              print(\"============================================================\")\n",
        "              print(f'bestMSE:: {best_mse},str: {ind}')\n",
        "              print(\"============================================================\")\n",
        "    print(\"Best architecture found:\", best_architecture)\n",
        "    return best_architecture\n",
        "\n",
        "# Create and train standard MLP for comparison\n",
        "def create_standard_mlp():\n",
        "    print(\"\\nCreating standard MLP...\")\n",
        "    model = Sequential([\n",
        "        Dense(10, input_dim=1, activation='relu'),\n",
        "        Dense(40, activation='relu'),\n",
        "        Dense(10, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(), loss='mse')\n",
        "    print(\"Standard MLP created and compiled.\")\n",
        "    model.summary()  # Display model summary\n",
        "    return model\n",
        "\n",
        "# Train the standard MLP\n",
        "print(\"\\nTraining standard MLP...\")\n",
        "mlp_model = create_standard_mlp()\n",
        "mlp_model.fit(X, y, epochs=50, verbose=0)\n",
        "mlp_mse = mlp_model.evaluate(X, y, verbose=0)\n",
        "print(\"Standard MLP MSE:\", mlp_mse)\n",
        "\n",
        "# Best architecture from genetic algorithm\n",
        "best_architecture = genetic_algorithm(population_size=5, generations=2, max_layers=3, max_neurons=100)\n",
        "print(\"\\nTraining model with best architecture from Genetic Algorithm...\")\n",
        "print(\"===============================================================\")\n",
        "print(\"===============================================================\")\n",
        "print(\"===============================================================\")\n",
        "print(\"===============================================================\")\n",
        "time.sleep(10)\n",
        "print(\"we will send the best structure to create model\")\n",
        "print(\"best\",best_architecture)\n",
        "time.sleep(10)\n",
        "genetic_model = create_model(best_architecture)\n",
        "genetic_model.fit(X, y, epochs=1000, verbose=0,callbacks=[PrintLoss()])\n",
        "genetic_mse = genetic_model.evaluate(X, y, verbose=0)\n",
        "print(\"Genetic Algorithm MLP MSE:\", genetic_mse)\n",
        "\n",
        "# Print MSE comparison\n",
        "print(\"\\nComparison of MSE:\")\n",
        "print(f\"Standard MLP MSE: {mlp_mse}\")\n",
        "print(f\"Genetic Algorithm MLP MSE: {genetic_mse}\")\n",
        "\n",
        "# Predictions for visualization\n",
        "y_pred_mlp = mlp_model.predict(X)\n",
        "y_pred_genetic = genetic_model.predict(X)\n",
        "\n",
        "# Plot results\n",
        "print(\"\\nPlotting results...\")\n",
        "plt.plot(X, y, label='Actual')\n",
        "plt.plot(X, y_pred_mlp, label='Standard MLP', linestyle='dashed')\n",
        "plt.plot(X, y_pred_genetic, label='Genetic Algorithm MLP', linestyle='dotted')\n",
        "plt.legend()\n",
        "plt.xlabel('Input')\n",
        "plt.ylabel('Target')\n",
        "plt.show()\n",
        "print(\"Plot displayed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gYB7L_cU2Vfk",
        "outputId": "896d7d38-5d93-415a-e2c8-9b097443b8c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded successfully!\n",
            "\n",
            "\n",
            "Training standard MLP...\n",
            "\n",
            "Creating standard MLP...\n",
            "Standard MLP created and compiled.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_381\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_381\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1274 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │              \u001b[38;5;34m20\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1275 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │             \u001b[38;5;34m440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1276 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m410\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1277 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1274 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1275 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1276 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">410</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1277 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m881\u001b[0m (3.44 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">881</span> (3.44 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m881\u001b[0m (3.44 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">881</span> (3.44 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard MLP MSE: 0.31134364008903503\n",
            "\n",
            "Starting Genetic Algorithm with population size 5 and 2 generations...\n",
            "\n",
            "\n",
            "Generating initial population of size 5 with max layers=3 and max neurons=100...\n",
            "Created architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [25, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Created architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [95], 'activation_functions': ['relu'], 'output_activation': 'sigmoid'}\n",
            "Created architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 54], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}\n",
            "Created architecture: {'num_hidden_layers': 3, 'neurons_per_layer': [26, 100, 14], 'activation_functions': ['relu', 'tanh', 'tanh'], 'output_activation': 'sigmoid'}\n",
            "Created architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [61], 'activation_functions': ['tanh'], 'output_activation': 'sigmoid'}\n",
            "Initial population generated.\n",
            "\n",
            "Generation 1/2\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [25, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [25, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_382\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_382\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1278 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │              \u001b[38;5;34m50\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1279 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)                  │           \u001b[38;5;34m1,638\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1280 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m64\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1278 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1279 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,638</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1280 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,752\u001b[0m (6.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,752</span> (6.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,752\u001b[0m (6.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,752</span> (6.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 36.47444152832031\n",
            "Epoch 2, Loss: 36.33987045288086\n",
            "Epoch 3, Loss: 36.228431701660156\n",
            "Epoch 4, Loss: 36.1359977722168\n",
            "Epoch 5, Loss: 36.059059143066406\n",
            "Epoch 6, Loss: 35.99471664428711\n",
            "Epoch 7, Loss: 35.941043853759766\n",
            "Epoch 8, Loss: 35.89700698852539\n",
            "Epoch 9, Loss: 35.85945129394531\n",
            "Epoch 10, Loss: 35.82693862915039\n",
            "Epoch 11, Loss: 35.798221588134766\n",
            "Epoch 12, Loss: 35.77299880981445\n",
            "Epoch 13, Loss: 35.750831604003906\n",
            "Epoch 14, Loss: 35.73131561279297\n",
            "Epoch 15, Loss: 35.714080810546875\n",
            "Epoch 16, Loss: 35.69879913330078\n",
            "Epoch 17, Loss: 35.68519973754883\n",
            "Epoch 18, Loss: 35.67303466796875\n",
            "Epoch 19, Loss: 35.6621208190918\n",
            "Epoch 20, Loss: 35.65229415893555\n",
            "Epoch 21, Loss: 35.64341354370117\n",
            "Epoch 22, Loss: 35.635372161865234\n",
            "Epoch 23, Loss: 35.628055572509766\n",
            "Epoch 24, Loss: 35.62139129638672\n",
            "Epoch 25, Loss: 35.615299224853516\n",
            "Epoch 26, Loss: 35.609718322753906\n",
            "Epoch 27, Loss: 35.604591369628906\n",
            "Epoch 28, Loss: 35.59988021850586\n",
            "Epoch 29, Loss: 35.59553146362305\n",
            "Epoch 30, Loss: 35.591514587402344\n",
            "Epoch 31, Loss: 35.58779525756836\n",
            "Epoch 32, Loss: 35.58433532714844\n",
            "Epoch 33, Loss: 35.58113098144531\n",
            "Epoch 34, Loss: 35.5781364440918\n",
            "Epoch 35, Loss: 35.57536697387695\n",
            "Epoch 36, Loss: 35.572776794433594\n",
            "Epoch 37, Loss: 35.57034683227539\n",
            "Epoch 38, Loss: 35.56808090209961\n",
            "Epoch 39, Loss: 35.56594467163086\n",
            "Epoch 40, Loss: 35.563941955566406\n",
            "Epoch 41, Loss: 35.56205749511719\n",
            "Epoch 42, Loss: 35.560279846191406\n",
            "Epoch 43, Loss: 35.558597564697266\n",
            "Epoch 44, Loss: 35.557010650634766\n",
            "Epoch 45, Loss: 35.55550765991211\n",
            "Epoch 46, Loss: 35.5540771484375\n",
            "Epoch 47, Loss: 35.5527229309082\n",
            "Epoch 48, Loss: 35.55142593383789\n",
            "Epoch 49, Loss: 35.55018615722656\n",
            "Epoch 50, Loss: 35.54899597167969\n",
            "Fitness (MSE) for this architecture: 35.54786682128906\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [95], 'activation_functions': ['relu'], 'output_activation': 'sigmoid'}\n",
            "Creating model with architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [95], 'activation_functions': ['relu'], 'output_activation': 'sigmoid'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_383\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_383\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1281 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m)                  │             \u001b[38;5;34m190\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1282 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m96\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1281 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1282 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m286\u001b[0m (1.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286</span> (1.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m286\u001b[0m (1.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286</span> (1.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 41.92530822753906\n",
            "Epoch 2, Loss: 41.6308479309082\n",
            "Epoch 3, Loss: 41.332332611083984\n",
            "Epoch 4, Loss: 41.03173065185547\n",
            "Epoch 5, Loss: 40.73111343383789\n",
            "Epoch 6, Loss: 40.4326286315918\n",
            "Epoch 7, Loss: 40.13839340209961\n",
            "Epoch 8, Loss: 39.85047912597656\n",
            "Epoch 9, Loss: 39.57078552246094\n",
            "Epoch 10, Loss: 39.301025390625\n",
            "Epoch 11, Loss: 39.04265213012695\n",
            "Epoch 12, Loss: 38.796836853027344\n",
            "Epoch 13, Loss: 38.5644416809082\n",
            "Epoch 14, Loss: 38.346031188964844\n",
            "Epoch 15, Loss: 38.141876220703125\n",
            "Epoch 16, Loss: 37.95199966430664\n",
            "Epoch 17, Loss: 37.776161193847656\n",
            "Epoch 18, Loss: 37.613983154296875\n",
            "Epoch 19, Loss: 37.46487045288086\n",
            "Epoch 20, Loss: 37.32826614379883\n",
            "Epoch 21, Loss: 37.20367431640625\n",
            "Epoch 22, Loss: 37.089900970458984\n",
            "Epoch 23, Loss: 36.986053466796875\n",
            "Epoch 24, Loss: 36.891361236572266\n",
            "Epoch 25, Loss: 36.8050537109375\n",
            "Epoch 26, Loss: 36.72640609741211\n",
            "Epoch 27, Loss: 36.654720306396484\n",
            "Epoch 28, Loss: 36.589359283447266\n",
            "Epoch 29, Loss: 36.52973556518555\n",
            "Epoch 30, Loss: 36.47529602050781\n",
            "Epoch 31, Loss: 36.42555236816406\n",
            "Epoch 32, Loss: 36.38005447387695\n",
            "Epoch 33, Loss: 36.338375091552734\n",
            "Epoch 34, Loss: 36.30012893676758\n",
            "Epoch 35, Loss: 36.26498794555664\n",
            "Epoch 36, Loss: 36.23265075683594\n",
            "Epoch 37, Loss: 36.202850341796875\n",
            "Epoch 38, Loss: 36.175357818603516\n",
            "Epoch 39, Loss: 36.149932861328125\n",
            "Epoch 40, Loss: 36.126399993896484\n",
            "Epoch 41, Loss: 36.104591369628906\n",
            "Epoch 42, Loss: 36.08433532714844\n",
            "Epoch 43, Loss: 36.06547927856445\n",
            "Epoch 44, Loss: 36.04789733886719\n",
            "Epoch 45, Loss: 36.03147888183594\n",
            "Epoch 46, Loss: 36.016117095947266\n",
            "Epoch 47, Loss: 36.00172805786133\n",
            "Epoch 48, Loss: 35.98823165893555\n",
            "Epoch 49, Loss: 35.97555923461914\n",
            "Epoch 50, Loss: 35.96363830566406\n",
            "Fitness (MSE) for this architecture: 35.95240783691406\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 54], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 54], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_384\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_384\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1283 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │              \u001b[38;5;34m62\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1284 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)                  │           \u001b[38;5;34m1,728\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1285 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m55\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1283 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1284 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1285 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,845\u001b[0m (7.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,845</span> (7.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,845\u001b[0m (7.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,845</span> (7.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 39.59836196899414\n",
            "Epoch 2, Loss: 37.77313995361328\n",
            "Epoch 3, Loss: 35.996212005615234\n",
            "Epoch 4, Loss: 34.268306732177734\n",
            "Epoch 5, Loss: 32.59013366699219\n",
            "Epoch 6, Loss: 30.96235466003418\n",
            "Epoch 7, Loss: 29.385515213012695\n",
            "Epoch 8, Loss: 27.86004638671875\n",
            "Epoch 9, Loss: 26.386274337768555\n",
            "Epoch 10, Loss: 24.964391708374023\n",
            "Epoch 11, Loss: 23.594444274902344\n",
            "Epoch 12, Loss: 22.27637481689453\n",
            "Epoch 13, Loss: 21.009986877441406\n",
            "Epoch 14, Loss: 19.794952392578125\n",
            "Epoch 15, Loss: 18.630821228027344\n",
            "Epoch 16, Loss: 17.51702308654785\n",
            "Epoch 17, Loss: 16.452903747558594\n",
            "Epoch 18, Loss: 15.437719345092773\n",
            "Epoch 19, Loss: 14.470656394958496\n",
            "Epoch 20, Loss: 13.5508451461792\n",
            "Epoch 21, Loss: 12.677359580993652\n",
            "Epoch 22, Loss: 11.849228858947754\n",
            "Epoch 23, Loss: 11.065428733825684\n",
            "Epoch 24, Loss: 10.324898719787598\n",
            "Epoch 25, Loss: 9.6265287399292\n",
            "Epoch 26, Loss: 8.969170570373535\n",
            "Epoch 27, Loss: 8.351633071899414\n",
            "Epoch 28, Loss: 7.7726969718933105\n",
            "Epoch 29, Loss: 7.231100082397461\n",
            "Epoch 30, Loss: 6.725552082061768\n",
            "Epoch 31, Loss: 6.254723072052002\n",
            "Epoch 32, Loss: 5.817288875579834\n",
            "Epoch 33, Loss: 5.411886692047119\n",
            "Epoch 34, Loss: 5.037137985229492\n",
            "Epoch 35, Loss: 4.691657066345215\n",
            "Epoch 36, Loss: 4.374048233032227\n",
            "Epoch 37, Loss: 4.082918643951416\n",
            "Epoch 38, Loss: 3.816863775253296\n",
            "Epoch 39, Loss: 3.5744943618774414\n",
            "Epoch 40, Loss: 3.3544492721557617\n",
            "Epoch 41, Loss: 3.1554925441741943\n",
            "Epoch 42, Loss: 2.976541757583618\n",
            "Epoch 43, Loss: 2.8158888816833496\n",
            "Epoch 44, Loss: 2.6721487045288086\n",
            "Epoch 45, Loss: 2.5440399646759033\n",
            "Epoch 46, Loss: 2.4303178787231445\n",
            "Epoch 47, Loss: 2.3297791481018066\n",
            "Epoch 48, Loss: 2.241262674331665\n",
            "Epoch 49, Loss: 2.163652181625366\n",
            "Epoch 50, Loss: 2.095885753631592\n",
            "Fitness (MSE) for this architecture: 2.036945343017578\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 3, 'neurons_per_layer': [26, 100, 14], 'activation_functions': ['relu', 'tanh', 'tanh'], 'output_activation': 'sigmoid'}\n",
            "Creating model with architecture: {'num_hidden_layers': 3, 'neurons_per_layer': [26, 100, 14], 'activation_functions': ['relu', 'tanh', 'tanh'], 'output_activation': 'sigmoid'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_385\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_385\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1286 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │              \u001b[38;5;34m52\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1287 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m2,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1288 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │           \u001b[38;5;34m1,414\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1289 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m15\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1286 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1287 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1288 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,414</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1289 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,181\u001b[0m (16.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,181</span> (16.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,181\u001b[0m (16.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,181</span> (16.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 42.3097038269043\n",
            "Epoch 2, Loss: 40.93303680419922\n",
            "Epoch 3, Loss: 39.59251403808594\n",
            "Epoch 4, Loss: 38.46041488647461\n",
            "Epoch 5, Loss: 37.60842514038086\n",
            "Epoch 6, Loss: 37.01286697387695\n",
            "Epoch 7, Loss: 36.61158752441406\n",
            "Epoch 8, Loss: 36.34367370605469\n",
            "Epoch 9, Loss: 36.16314697265625\n",
            "Epoch 10, Loss: 36.03909683227539\n",
            "Epoch 11, Loss: 35.951725006103516\n",
            "Epoch 12, Loss: 35.88858413696289\n",
            "Epoch 13, Loss: 35.841793060302734\n",
            "Epoch 14, Loss: 35.80630111694336\n",
            "Epoch 15, Loss: 35.7787971496582\n",
            "Epoch 16, Loss: 35.7570686340332\n",
            "Epoch 17, Loss: 35.739601135253906\n",
            "Epoch 18, Loss: 35.72533416748047\n",
            "Epoch 19, Loss: 35.7135124206543\n",
            "Epoch 20, Loss: 35.703590393066406\n",
            "Epoch 21, Loss: 35.69516372680664\n",
            "Epoch 22, Loss: 35.68792724609375\n",
            "Epoch 23, Loss: 35.681644439697266\n",
            "Epoch 24, Loss: 35.676151275634766\n",
            "Epoch 25, Loss: 35.67129898071289\n",
            "Epoch 26, Loss: 35.66697692871094\n",
            "Epoch 27, Loss: 35.6630973815918\n",
            "Epoch 28, Loss: 35.65959548950195\n",
            "Epoch 29, Loss: 35.65640640258789\n",
            "Epoch 30, Loss: 35.65349197387695\n",
            "Epoch 31, Loss: 35.65080642700195\n",
            "Epoch 32, Loss: 35.648319244384766\n",
            "Epoch 33, Loss: 35.646018981933594\n",
            "Epoch 34, Loss: 35.643863677978516\n",
            "Epoch 35, Loss: 35.641841888427734\n",
            "Epoch 36, Loss: 35.63993453979492\n",
            "Epoch 37, Loss: 35.63813781738281\n",
            "Epoch 38, Loss: 35.636436462402344\n",
            "Epoch 39, Loss: 35.63481140136719\n",
            "Epoch 40, Loss: 35.63327407836914\n",
            "Epoch 41, Loss: 35.631805419921875\n",
            "Epoch 42, Loss: 35.630393981933594\n",
            "Epoch 43, Loss: 35.62904739379883\n",
            "Epoch 44, Loss: 35.62775802612305\n",
            "Epoch 45, Loss: 35.62651824951172\n",
            "Epoch 46, Loss: 35.62532424926758\n",
            "Epoch 47, Loss: 35.62417984008789\n",
            "Epoch 48, Loss: 35.62307357788086\n",
            "Epoch 49, Loss: 35.622013092041016\n",
            "Epoch 50, Loss: 35.62098693847656\n",
            "Fitness (MSE) for this architecture: 35.619998931884766\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [61], 'activation_functions': ['tanh'], 'output_activation': 'sigmoid'}\n",
            "Creating model with architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [61], 'activation_functions': ['tanh'], 'output_activation': 'sigmoid'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_386\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_386\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1290 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  │             \u001b[38;5;34m122\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1291 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m62\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1290 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1291 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m184\u001b[0m (736.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">184</span> (736.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m184\u001b[0m (736.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">184</span> (736.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 40.000301361083984\n",
            "Epoch 2, Loss: 39.80678939819336\n",
            "Epoch 3, Loss: 39.617000579833984\n",
            "Epoch 4, Loss: 39.4314079284668\n",
            "Epoch 5, Loss: 39.250457763671875\n",
            "Epoch 6, Loss: 39.074562072753906\n",
            "Epoch 7, Loss: 38.90406799316406\n",
            "Epoch 8, Loss: 38.73927307128906\n",
            "Epoch 9, Loss: 38.58042907714844\n",
            "Epoch 10, Loss: 38.42771911621094\n",
            "Epoch 11, Loss: 38.28127670288086\n",
            "Epoch 12, Loss: 38.14117431640625\n",
            "Epoch 13, Loss: 38.0074462890625\n",
            "Epoch 14, Loss: 37.880062103271484\n",
            "Epoch 15, Loss: 37.75896453857422\n",
            "Epoch 16, Loss: 37.64405822753906\n",
            "Epoch 17, Loss: 37.535194396972656\n",
            "Epoch 18, Loss: 37.432220458984375\n",
            "Epoch 19, Loss: 37.33495330810547\n",
            "Epoch 20, Loss: 37.243186950683594\n",
            "Epoch 21, Loss: 37.15670394897461\n",
            "Epoch 22, Loss: 37.07527160644531\n",
            "Epoch 23, Loss: 36.9986686706543\n",
            "Epoch 24, Loss: 36.9266471862793\n",
            "Epoch 25, Loss: 36.858970642089844\n",
            "Epoch 26, Loss: 36.79541015625\n",
            "Epoch 27, Loss: 36.73573303222656\n",
            "Epoch 28, Loss: 36.67970275878906\n",
            "Epoch 29, Loss: 36.627113342285156\n",
            "Epoch 30, Loss: 36.57775115966797\n",
            "Epoch 31, Loss: 36.53140640258789\n",
            "Epoch 32, Loss: 36.487892150878906\n",
            "Epoch 33, Loss: 36.447025299072266\n",
            "Epoch 34, Loss: 36.408626556396484\n",
            "Epoch 35, Loss: 36.37254333496094\n",
            "Epoch 36, Loss: 36.33860778808594\n",
            "Epoch 37, Loss: 36.30668640136719\n",
            "Epoch 38, Loss: 36.27663803100586\n",
            "Epoch 39, Loss: 36.24833679199219\n",
            "Epoch 40, Loss: 36.22166061401367\n",
            "Epoch 41, Loss: 36.19650650024414\n",
            "Epoch 42, Loss: 36.17276382446289\n",
            "Epoch 43, Loss: 36.15034103393555\n",
            "Epoch 44, Loss: 36.129146575927734\n",
            "Epoch 45, Loss: 36.10909652709961\n",
            "Epoch 46, Loss: 36.09012222290039\n",
            "Epoch 47, Loss: 36.072139739990234\n",
            "Epoch 48, Loss: 36.05508804321289\n",
            "Epoch 49, Loss: 36.03891372680664\n",
            "Epoch 50, Loss: 36.0235481262207\n",
            "Fitness (MSE) for this architecture: 36.008949279785156\n",
            "###############################################################\n",
            "\n",
            "Selecting parents based on fitness scores...\n",
            "Selected parents: [{'num_hidden_layers': 2, 'neurons_per_layer': [31, 54], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}, {'num_hidden_layers': 2, 'neurons_per_layer': [25, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}]\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 3, 'neurons_per_layer': [64, 27, 16], 'activation_functions': ['sigmoid', 'tanh', 'sigmoid'], 'output_activation': 'relu'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'relu'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 3, 'neurons_per_layer': [57, 14, 46], 'activation_functions': ['relu', 'relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'tanh'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 3, 'neurons_per_layer': [77, 46, 60], 'activation_functions': ['sigmoid', 'relu', 'relu'], 'output_activation': 'sigmoid'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [64, 97], 'activation_functions': ['relu', 'sigmoid'], 'output_activation': 'tanh'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 54], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [87], 'activation_functions': ['relu'], 'output_activation': 'tanh'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 54], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}\n",
            "Completed generation 1\n",
            "--------------------------------------------------------------------------------\n",
            "============================================================\n",
            "bestMSE:: 35.54786682128906,str: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'relu'}\n",
            "============================================================\n",
            "============================================================\n",
            "bestMSE:: 2.036945343017578,str: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "============================================================\n",
            "Generation 2/2\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'relu'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'relu'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_387\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_387\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1292 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │              \u001b[38;5;34m62\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1293 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)                  │           \u001b[38;5;34m2,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1294 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m64\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1292 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1293 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1294 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,142\u001b[0m (8.37 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142</span> (8.37 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,142\u001b[0m (8.37 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142</span> (8.37 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 27.549335479736328\n",
            "Epoch 2, Loss: 25.759862899780273\n",
            "Epoch 3, Loss: 24.11454963684082\n",
            "Epoch 4, Loss: 22.527109146118164\n",
            "Epoch 5, Loss: 20.99175453186035\n",
            "Epoch 6, Loss: 19.51466178894043\n",
            "Epoch 7, Loss: 18.089366912841797\n",
            "Epoch 8, Loss: 16.71695899963379\n",
            "Epoch 9, Loss: 15.398334503173828\n",
            "Epoch 10, Loss: 14.134926795959473\n",
            "Epoch 11, Loss: 12.95489501953125\n",
            "Epoch 12, Loss: 11.872092247009277\n",
            "Epoch 13, Loss: 10.850646018981934\n",
            "Epoch 14, Loss: 9.890952110290527\n",
            "Epoch 15, Loss: 8.977603912353516\n",
            "Epoch 16, Loss: 8.111098289489746\n",
            "Epoch 17, Loss: 7.2918901443481445\n",
            "Epoch 18, Loss: 6.520359516143799\n",
            "Epoch 19, Loss: 5.796851634979248\n",
            "Epoch 20, Loss: 5.121577739715576\n",
            "Epoch 21, Loss: 4.494665622711182\n",
            "Epoch 22, Loss: 3.917830467224121\n",
            "Epoch 23, Loss: 3.388822317123413\n",
            "Epoch 24, Loss: 2.9068260192871094\n",
            "Epoch 25, Loss: 2.4712533950805664\n",
            "Epoch 26, Loss: 2.0812506675720215\n",
            "Epoch 27, Loss: 1.7357174158096313\n",
            "Epoch 28, Loss: 1.433750033378601\n",
            "Epoch 29, Loss: 1.1731375455856323\n",
            "Epoch 30, Loss: 0.9518083930015564\n",
            "Epoch 31, Loss: 0.7675422430038452\n",
            "Epoch 32, Loss: 0.6178408265113831\n",
            "Epoch 33, Loss: 0.499942421913147\n",
            "Epoch 34, Loss: 0.41085803508758545\n",
            "Epoch 35, Loss: 0.347413033246994\n",
            "Epoch 36, Loss: 0.30629822611808777\n",
            "Epoch 37, Loss: 0.28413501381874084\n",
            "Epoch 38, Loss: 0.2775435447692871\n",
            "Epoch 39, Loss: 0.28321540355682373\n",
            "Epoch 40, Loss: 0.29799067974090576\n",
            "Epoch 41, Loss: 0.31894418597221375\n",
            "Epoch 42, Loss: 0.3433893918991089\n",
            "Epoch 43, Loss: 0.36899498105049133\n",
            "Epoch 44, Loss: 0.3938027322292328\n",
            "Epoch 45, Loss: 0.41624510288238525\n",
            "Epoch 46, Loss: 0.43515145778656006\n",
            "Epoch 47, Loss: 0.4497348964214325\n",
            "Epoch 48, Loss: 0.45956695079803467\n",
            "Epoch 49, Loss: 0.4645446836948395\n",
            "Epoch 50, Loss: 0.46483075618743896\n",
            "Fitness (MSE) for this architecture: 0.4608074426651001\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'tanh'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'tanh'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_388\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_388\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1295 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │              \u001b[38;5;34m62\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1296 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)                  │           \u001b[38;5;34m2,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1297 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m64\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1295 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1296 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1297 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,142\u001b[0m (8.37 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142</span> (8.37 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,142\u001b[0m (8.37 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142</span> (8.37 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 40.88372802734375\n",
            "Epoch 2, Loss: 39.46267318725586\n",
            "Epoch 3, Loss: 38.385589599609375\n",
            "Epoch 4, Loss: 37.601932525634766\n",
            "Epoch 5, Loss: 37.04561996459961\n",
            "Epoch 6, Loss: 36.65606689453125\n",
            "Epoch 7, Loss: 36.38256072998047\n",
            "Epoch 8, Loss: 36.18740463256836\n",
            "Epoch 9, Loss: 36.04631423950195\n",
            "Epoch 10, Loss: 35.94272994995117\n",
            "Epoch 11, Loss: 35.865413665771484\n",
            "Epoch 12, Loss: 35.8067512512207\n",
            "Epoch 13, Loss: 35.761531829833984\n",
            "Epoch 14, Loss: 35.72614288330078\n",
            "Epoch 15, Loss: 35.698055267333984\n",
            "Epoch 16, Loss: 35.67546463012695\n",
            "Epoch 17, Loss: 35.657081604003906\n",
            "Epoch 18, Loss: 35.64195251464844\n",
            "Epoch 19, Loss: 35.62936782836914\n",
            "Epoch 20, Loss: 35.61880874633789\n",
            "Epoch 21, Loss: 35.609867095947266\n",
            "Epoch 22, Loss: 35.602237701416016\n",
            "Epoch 23, Loss: 35.595680236816406\n",
            "Epoch 24, Loss: 35.59001159667969\n",
            "Epoch 25, Loss: 35.5850715637207\n",
            "Epoch 26, Loss: 35.580745697021484\n",
            "Epoch 27, Loss: 35.57693862915039\n",
            "Epoch 28, Loss: 35.57356262207031\n",
            "Epoch 29, Loss: 35.57057189941406\n",
            "Epoch 30, Loss: 35.56789779663086\n",
            "Epoch 31, Loss: 35.565494537353516\n",
            "Epoch 32, Loss: 35.56333541870117\n",
            "Epoch 33, Loss: 35.56138610839844\n",
            "Epoch 34, Loss: 35.559608459472656\n",
            "Epoch 35, Loss: 35.55799865722656\n",
            "Epoch 36, Loss: 35.556522369384766\n",
            "Epoch 37, Loss: 35.555171966552734\n",
            "Epoch 38, Loss: 35.553932189941406\n",
            "Epoch 39, Loss: 35.552791595458984\n",
            "Epoch 40, Loss: 35.55173110961914\n",
            "Epoch 41, Loss: 35.55074691772461\n",
            "Epoch 42, Loss: 35.54983901977539\n",
            "Epoch 43, Loss: 35.54898452758789\n",
            "Epoch 44, Loss: 35.54819107055664\n",
            "Epoch 45, Loss: 35.547447204589844\n",
            "Epoch 46, Loss: 35.54674530029297\n",
            "Epoch 47, Loss: 35.546085357666016\n",
            "Epoch 48, Loss: 35.54545974731445\n",
            "Epoch 49, Loss: 35.54487228393555\n",
            "Epoch 50, Loss: 35.5443115234375\n",
            "Fitness (MSE) for this architecture: 35.54377746582031\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_389\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_389\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1298 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │              \u001b[38;5;34m62\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1299 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)                  │           \u001b[38;5;34m2,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1300 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m64\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1298 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1299 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1300 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,142\u001b[0m (8.37 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142</span> (8.37 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,142\u001b[0m (8.37 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142</span> (8.37 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 56.51749038696289\n",
            "Epoch 2, Loss: 55.7190055847168\n",
            "Epoch 3, Loss: 54.718265533447266\n",
            "Epoch 4, Loss: 53.51250076293945\n",
            "Epoch 5, Loss: 52.07331848144531\n",
            "Epoch 6, Loss: 50.414676666259766\n",
            "Epoch 7, Loss: 48.5860710144043\n",
            "Epoch 8, Loss: 46.641475677490234\n",
            "Epoch 9, Loss: 44.706504821777344\n",
            "Epoch 10, Loss: 42.91152572631836\n",
            "Epoch 11, Loss: 41.35157012939453\n",
            "Epoch 12, Loss: 40.0699462890625\n",
            "Epoch 13, Loss: 39.06261444091797\n",
            "Epoch 14, Loss: 38.30302810668945\n",
            "Epoch 15, Loss: 37.72842025756836\n",
            "Epoch 16, Loss: 37.295589447021484\n",
            "Epoch 17, Loss: 36.971736907958984\n",
            "Epoch 18, Loss: 36.729515075683594\n",
            "Epoch 19, Loss: 36.542625427246094\n",
            "Epoch 20, Loss: 36.39688491821289\n",
            "Epoch 21, Loss: 36.28187561035156\n",
            "Epoch 22, Loss: 36.19002151489258\n",
            "Epoch 23, Loss: 36.11579895019531\n",
            "Epoch 24, Loss: 36.055213928222656\n",
            "Epoch 25, Loss: 36.00521469116211\n",
            "Epoch 26, Loss: 35.96357345581055\n",
            "Epoch 27, Loss: 35.928688049316406\n",
            "Epoch 28, Loss: 35.89949035644531\n",
            "Epoch 29, Loss: 35.874507904052734\n",
            "Epoch 30, Loss: 35.853004455566406\n",
            "Epoch 31, Loss: 35.83451843261719\n",
            "Epoch 32, Loss: 35.81845474243164\n",
            "Epoch 33, Loss: 35.804351806640625\n",
            "Epoch 34, Loss: 35.79190444946289\n",
            "Epoch 35, Loss: 35.7808723449707\n",
            "Epoch 36, Loss: 35.771053314208984\n",
            "Epoch 37, Loss: 35.76224136352539\n",
            "Epoch 38, Loss: 35.75428771972656\n",
            "Epoch 39, Loss: 35.74708557128906\n",
            "Epoch 40, Loss: 35.74052429199219\n",
            "Epoch 41, Loss: 35.7345085144043\n",
            "Epoch 42, Loss: 35.7289924621582\n",
            "Epoch 43, Loss: 35.72390365600586\n",
            "Epoch 44, Loss: 35.71919250488281\n",
            "Epoch 45, Loss: 35.714820861816406\n",
            "Epoch 46, Loss: 35.71074295043945\n",
            "Epoch 47, Loss: 35.70693588256836\n",
            "Epoch 48, Loss: 35.703365325927734\n",
            "Epoch 49, Loss: 35.700008392333984\n",
            "Epoch 50, Loss: 35.69684982299805\n",
            "Fitness (MSE) for this architecture: 35.69386291503906\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [64, 54], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [64, 54], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_390\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_390\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1301 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1302 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)                  │           \u001b[38;5;34m3,510\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1303 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m55\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1301 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1302 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,510</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1303 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,693\u001b[0m (14.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,693</span> (14.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,693\u001b[0m (14.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,693</span> (14.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 48.50399398803711\n",
            "Epoch 2, Loss: 46.41257095336914\n",
            "Epoch 3, Loss: 44.39078140258789\n",
            "Epoch 4, Loss: 42.57081604003906\n",
            "Epoch 5, Loss: 41.03448486328125\n",
            "Epoch 6, Loss: 39.80326461791992\n",
            "Epoch 7, Loss: 38.858036041259766\n",
            "Epoch 8, Loss: 38.15556716918945\n",
            "Epoch 9, Loss: 37.62620544433594\n",
            "Epoch 10, Loss: 37.22784423828125\n",
            "Epoch 11, Loss: 36.92657470703125\n",
            "Epoch 12, Loss: 36.69667053222656\n",
            "Epoch 13, Loss: 36.51927185058594\n",
            "Epoch 14, Loss: 36.380619049072266\n",
            "Epoch 15, Loss: 36.270816802978516\n",
            "Epoch 16, Loss: 36.1827507019043\n",
            "Epoch 17, Loss: 36.11128234863281\n",
            "Epoch 18, Loss: 36.052833557128906\n",
            "Epoch 19, Loss: 36.0028190612793\n",
            "Epoch 20, Loss: 35.960594177246094\n",
            "Epoch 21, Loss: 35.924869537353516\n",
            "Epoch 22, Loss: 35.894142150878906\n",
            "Epoch 23, Loss: 35.867431640625\n",
            "Epoch 24, Loss: 35.84410095214844\n",
            "Epoch 25, Loss: 35.82359313964844\n",
            "Epoch 26, Loss: 35.805484771728516\n",
            "Epoch 27, Loss: 35.78941345214844\n",
            "Epoch 28, Loss: 35.77507400512695\n",
            "Epoch 29, Loss: 35.762229919433594\n",
            "Epoch 30, Loss: 35.75066375732422\n",
            "Epoch 31, Loss: 35.74020767211914\n",
            "Epoch 32, Loss: 35.730716705322266\n",
            "Epoch 33, Loss: 35.72208023071289\n",
            "Epoch 34, Loss: 35.714176177978516\n",
            "Epoch 35, Loss: 35.70692443847656\n",
            "Epoch 36, Loss: 35.70024871826172\n",
            "Epoch 37, Loss: 35.6940803527832\n",
            "Epoch 38, Loss: 35.68836975097656\n",
            "Epoch 39, Loss: 35.68305969238281\n",
            "Epoch 40, Loss: 35.67811584472656\n",
            "Epoch 41, Loss: 35.673492431640625\n",
            "Epoch 42, Loss: 35.66916275024414\n",
            "Epoch 43, Loss: 35.665096282958984\n",
            "Epoch 44, Loss: 35.6612663269043\n",
            "Epoch 45, Loss: 35.65764236450195\n",
            "Epoch 46, Loss: 35.65420913696289\n",
            "Epoch 47, Loss: 35.65095901489258\n",
            "Epoch 48, Loss: 35.64786911010742\n",
            "Epoch 49, Loss: 35.64493179321289\n",
            "Epoch 50, Loss: 35.64212417602539\n",
            "Fitness (MSE) for this architecture: 35.639442443847656\n",
            "###############################################################\n",
            "\n",
            "Evaluating fitness for architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [40, 54], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [40, 54], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_391\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_391\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1304 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1305 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)                  │           \u001b[38;5;34m2,214\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1306 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m55\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1304 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1305 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,214</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1306 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,349\u001b[0m (9.18 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,349</span> (9.18 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,349\u001b[0m (9.18 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,349</span> (9.18 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 46.7271728515625\n",
            "Epoch 2, Loss: 46.7271728515625\n",
            "Epoch 3, Loss: 46.7271728515625\n",
            "Epoch 4, Loss: 46.7271728515625\n",
            "Epoch 5, Loss: 46.7271728515625\n",
            "Epoch 6, Loss: 46.7271728515625\n",
            "Epoch 7, Loss: 46.7271728515625\n",
            "Epoch 8, Loss: 46.7271728515625\n",
            "Epoch 9, Loss: 46.7271728515625\n",
            "Epoch 10, Loss: 46.7271728515625\n",
            "Epoch 11, Loss: 46.7271728515625\n",
            "Epoch 12, Loss: 46.7271728515625\n",
            "Epoch 13, Loss: 46.7271728515625\n",
            "Epoch 14, Loss: 46.7271728515625\n",
            "Epoch 15, Loss: 46.7271728515625\n",
            "Epoch 16, Loss: 46.7271728515625\n",
            "Epoch 17, Loss: 46.7271728515625\n",
            "Epoch 18, Loss: 46.7271728515625\n",
            "Epoch 19, Loss: 46.7271728515625\n",
            "Epoch 20, Loss: 46.7271728515625\n",
            "Epoch 21, Loss: 46.7271728515625\n",
            "Epoch 22, Loss: 46.7271728515625\n",
            "Epoch 23, Loss: 46.7271728515625\n",
            "Epoch 24, Loss: 46.7271728515625\n",
            "Epoch 25, Loss: 46.7271728515625\n",
            "Epoch 26, Loss: 46.7271728515625\n",
            "Epoch 27, Loss: 46.7271728515625\n",
            "Epoch 28, Loss: 46.7271728515625\n",
            "Epoch 29, Loss: 46.7271728515625\n",
            "Epoch 30, Loss: 46.7271728515625\n",
            "Epoch 31, Loss: 46.7271728515625\n",
            "Epoch 32, Loss: 46.7271728515625\n",
            "Epoch 33, Loss: 46.7271728515625\n",
            "Epoch 34, Loss: 46.7271728515625\n",
            "Epoch 35, Loss: 46.7271728515625\n",
            "Epoch 36, Loss: 46.7271728515625\n",
            "Epoch 37, Loss: 46.7271728515625\n",
            "Epoch 38, Loss: 46.7271728515625\n",
            "Epoch 39, Loss: 46.7271728515625\n",
            "Epoch 40, Loss: 46.7271728515625\n",
            "Epoch 41, Loss: 46.7271728515625\n",
            "Epoch 42, Loss: 46.7271728515625\n",
            "Epoch 43, Loss: 46.7271728515625\n",
            "Epoch 44, Loss: 46.7271728515625\n",
            "Epoch 45, Loss: 46.7271728515625\n",
            "Epoch 46, Loss: 46.7271728515625\n",
            "Epoch 47, Loss: 46.7271728515625\n",
            "Epoch 48, Loss: 46.7271728515625\n",
            "Epoch 49, Loss: 46.7271728515625\n",
            "Epoch 50, Loss: 46.7271728515625\n",
            "Fitness (MSE) for this architecture: 46.7271728515625\n",
            "###############################################################\n",
            "\n",
            "Selecting parents based on fitness scores...\n",
            "Selected parents: [{'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'relu'}, {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'tanh'}]\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 3, 'neurons_per_layer': [91, 23, 55], 'activation_functions': ['tanh', 'tanh', 'relu'], 'output_activation': 'relu'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'relu'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [30, 46], 'activation_functions': ['sigmoid', 'tanh'], 'output_activation': 'sigmoid'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [50], 'activation_functions': ['sigmoid'], 'output_activation': 'sigmoid'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'tanh'], 'output_activation': 'tanh'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [11], 'activation_functions': ['relu'], 'output_activation': 'relu'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'relu'}\n",
            "\n",
            "Performing crossover...\n",
            "Created architecture: {'num_hidden_layers': 1, 'neurons_per_layer': [61], 'activation_functions': ['tanh'], 'output_activation': 'relu'}\n",
            "Created child architecture after crossover: {'num_hidden_layers': 2, 'neurons_per_layer': [31, 63], 'activation_functions': ['relu', 'relu'], 'output_activation': 'tanh'}\n",
            "Completed generation 2\n",
            "--------------------------------------------------------------------------------\n",
            "============================================================\n",
            "bestMSE:: 0.4608074426651001,str: {'num_hidden_layers': 2, 'neurons_per_layer': [90, 63], 'activation_functions': ['sigmoid', 'tanh'], 'output_activation': 'relu'}\n",
            "============================================================\n",
            "Best architecture found: {'num_hidden_layers': 2, 'neurons_per_layer': [90, 63], 'activation_functions': ['sigmoid', 'tanh'], 'output_activation': 'relu'}\n",
            "\n",
            "Training model with best architecture from Genetic Algorithm...\n",
            "===============================================================\n",
            "===============================================================\n",
            "===============================================================\n",
            "===============================================================\n",
            "we will send the best structure to create model\n",
            "best {'num_hidden_layers': 2, 'neurons_per_layer': [90, 63], 'activation_functions': ['sigmoid', 'tanh'], 'output_activation': 'relu'}\n",
            "Creating model with architecture: {'num_hidden_layers': 2, 'neurons_per_layer': [90, 63], 'activation_functions': ['sigmoid', 'tanh'], 'output_activation': 'relu'}\n",
            "Model created and compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_392\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_392\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1307 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m)                  │             \u001b[38;5;34m180\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1308 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)                  │           \u001b[38;5;34m5,733\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1309 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m64\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1307 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1308 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,733</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1309 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,977\u001b[0m (23.35 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,977</span> (23.35 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,977\u001b[0m (23.35 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,977</span> (23.35 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 46.71635437011719\n",
            "Epoch 2, Loss: 44.86421585083008\n",
            "Epoch 3, Loss: 41.304893493652344\n",
            "Epoch 4, Loss: 37.46676254272461\n",
            "Epoch 5, Loss: 33.70628356933594\n",
            "Epoch 6, Loss: 30.158275604248047\n",
            "Epoch 7, Loss: 26.887189865112305\n",
            "Epoch 8, Loss: 23.92512321472168\n",
            "Epoch 9, Loss: 21.285795211791992\n",
            "Epoch 10, Loss: 18.97080421447754\n",
            "Epoch 11, Loss: 16.972740173339844\n",
            "Epoch 12, Loss: 15.277304649353027\n",
            "Epoch 13, Loss: 13.864910125732422\n",
            "Epoch 14, Loss: 12.712079048156738\n",
            "Epoch 15, Loss: 11.792675018310547\n",
            "Epoch 16, Loss: 11.07901668548584\n",
            "Epoch 17, Loss: 10.54287052154541\n",
            "Epoch 18, Loss: 10.156340599060059\n",
            "Epoch 19, Loss: 9.892611503601074\n",
            "Epoch 20, Loss: 9.726558685302734\n",
            "Epoch 21, Loss: 9.63519287109375\n",
            "Epoch 22, Loss: 9.598007202148438\n",
            "Epoch 23, Loss: 9.597119331359863\n",
            "Epoch 24, Loss: 9.617384910583496\n",
            "Epoch 25, Loss: 9.64633846282959\n",
            "Epoch 26, Loss: 9.674099922180176\n",
            "Epoch 27, Loss: 9.693181991577148\n",
            "Epoch 28, Loss: 9.698262214660645\n",
            "Epoch 29, Loss: 9.685914039611816\n",
            "Epoch 30, Loss: 9.654314994812012\n",
            "Epoch 31, Loss: 9.602987289428711\n",
            "Epoch 32, Loss: 9.532515525817871\n",
            "Epoch 33, Loss: 9.44430923461914\n",
            "Epoch 34, Loss: 9.340385437011719\n",
            "Epoch 35, Loss: 9.22316837310791\n",
            "Epoch 36, Loss: 9.095324516296387\n",
            "Epoch 37, Loss: 8.959615707397461\n",
            "Epoch 38, Loss: 8.8187837600708\n",
            "Epoch 39, Loss: 8.675423622131348\n",
            "Epoch 40, Loss: 8.531927108764648\n",
            "Epoch 41, Loss: 8.390393257141113\n",
            "Epoch 42, Loss: 8.252593994140625\n",
            "Epoch 43, Loss: 8.119932174682617\n",
            "Epoch 44, Loss: 7.99343729019165\n",
            "Epoch 45, Loss: 7.873748779296875\n",
            "Epoch 46, Loss: 7.761146068572998\n",
            "Epoch 47, Loss: 7.655564785003662\n",
            "Epoch 48, Loss: 7.556652545928955\n",
            "Epoch 49, Loss: 7.463796615600586\n",
            "Epoch 50, Loss: 7.376194477081299\n",
            "Epoch 51, Loss: 7.292898654937744\n",
            "Epoch 52, Loss: 7.212889194488525\n",
            "Epoch 53, Loss: 7.13511848449707\n",
            "Epoch 54, Loss: 7.058567523956299\n",
            "Epoch 55, Loss: 6.982292652130127\n",
            "Epoch 56, Loss: 6.905459403991699\n",
            "Epoch 57, Loss: 6.827366828918457\n",
            "Epoch 58, Loss: 6.7474751472473145\n",
            "Epoch 59, Loss: 6.665403842926025\n",
            "Epoch 60, Loss: 6.580942153930664\n",
            "Epoch 61, Loss: 6.49403190612793\n",
            "Epoch 62, Loss: 6.404754638671875\n",
            "Epoch 63, Loss: 6.3133087158203125\n",
            "Epoch 64, Loss: 6.219986438751221\n",
            "Epoch 65, Loss: 6.125131607055664\n",
            "Epoch 66, Loss: 6.029130935668945\n",
            "Epoch 67, Loss: 5.932356357574463\n",
            "Epoch 68, Loss: 5.835163593292236\n",
            "Epoch 69, Loss: 5.737854480743408\n",
            "Epoch 70, Loss: 5.640675067901611\n",
            "Epoch 71, Loss: 5.5438032150268555\n",
            "Epoch 72, Loss: 5.447337627410889\n",
            "Epoch 73, Loss: 5.351320266723633\n",
            "Epoch 74, Loss: 5.255733013153076\n",
            "Epoch 75, Loss: 5.160513401031494\n",
            "Epoch 76, Loss: 5.065577983856201\n",
            "Epoch 77, Loss: 4.970824718475342\n",
            "Epoch 78, Loss: 4.876158714294434\n",
            "Epoch 79, Loss: 4.7815022468566895\n",
            "Epoch 80, Loss: 4.686804294586182\n",
            "Epoch 81, Loss: 4.592050075531006\n",
            "Epoch 82, Loss: 4.497252941131592\n",
            "Epoch 83, Loss: 4.402468681335449\n",
            "Epoch 84, Loss: 4.307777404785156\n",
            "Epoch 85, Loss: 4.213284015655518\n",
            "Epoch 86, Loss: 4.119106769561768\n",
            "Epoch 87, Loss: 4.0253682136535645\n",
            "Epoch 88, Loss: 3.932178258895874\n",
            "Epoch 89, Loss: 3.839643716812134\n",
            "Epoch 90, Loss: 3.747844696044922\n",
            "Epoch 91, Loss: 3.6568429470062256\n",
            "Epoch 92, Loss: 3.5666747093200684\n",
            "Epoch 93, Loss: 3.4773621559143066\n",
            "Epoch 94, Loss: 3.388909101486206\n",
            "Epoch 95, Loss: 3.301316738128662\n",
            "Epoch 96, Loss: 3.2145814895629883\n",
            "Epoch 97, Loss: 3.128708600997925\n",
            "Epoch 98, Loss: 3.0437142848968506\n",
            "Epoch 99, Loss: 2.9596261978149414\n",
            "Epoch 100, Loss: 2.8764917850494385\n",
            "Epoch 101, Loss: 2.7943642139434814\n",
            "Epoch 102, Loss: 2.7133138179779053\n",
            "Epoch 103, Loss: 2.6334142684936523\n",
            "Epoch 104, Loss: 2.5547401905059814\n",
            "Epoch 105, Loss: 2.4773688316345215\n",
            "Epoch 106, Loss: 2.401366710662842\n",
            "Epoch 107, Loss: 2.326793909072876\n",
            "Epoch 108, Loss: 2.25370192527771\n",
            "Epoch 109, Loss: 2.182133674621582\n",
            "Epoch 110, Loss: 2.1121249198913574\n",
            "Epoch 111, Loss: 2.0437047481536865\n",
            "Epoch 112, Loss: 1.9768989086151123\n",
            "Epoch 113, Loss: 1.9117306470870972\n",
            "Epoch 114, Loss: 1.8482238054275513\n",
            "Epoch 115, Loss: 1.786400318145752\n",
            "Epoch 116, Loss: 1.726282000541687\n",
            "Epoch 117, Loss: 1.6678879261016846\n",
            "Epoch 118, Loss: 1.6112391948699951\n",
            "Epoch 119, Loss: 1.5563489198684692\n",
            "Epoch 120, Loss: 1.5032272338867188\n",
            "Epoch 121, Loss: 1.4518802165985107\n",
            "Epoch 122, Loss: 1.4023069143295288\n",
            "Epoch 123, Loss: 1.3545016050338745\n",
            "Epoch 124, Loss: 1.3084527254104614\n",
            "Epoch 125, Loss: 1.2641465663909912\n",
            "Epoch 126, Loss: 1.2215628623962402\n",
            "Epoch 127, Loss: 1.1806801557540894\n",
            "Epoch 128, Loss: 1.1414748430252075\n",
            "Epoch 129, Loss: 1.1039215326309204\n",
            "Epoch 130, Loss: 1.0679923295974731\n",
            "Epoch 131, Loss: 1.0336582660675049\n",
            "Epoch 132, Loss: 1.0008864402770996\n",
            "Epoch 133, Loss: 0.9696443676948547\n",
            "Epoch 134, Loss: 0.9398969411849976\n",
            "Epoch 135, Loss: 0.9116010069847107\n",
            "Epoch 136, Loss: 0.8847208619117737\n",
            "Epoch 137, Loss: 0.8592091202735901\n",
            "Epoch 138, Loss: 0.8350228667259216\n",
            "Epoch 139, Loss: 0.8121160864830017\n",
            "Epoch 140, Loss: 0.7904411554336548\n",
            "Epoch 141, Loss: 0.7699491381645203\n",
            "Epoch 142, Loss: 0.7505949139595032\n",
            "Epoch 143, Loss: 0.7323300838470459\n",
            "Epoch 144, Loss: 0.7151073813438416\n",
            "Epoch 145, Loss: 0.6988793611526489\n",
            "Epoch 146, Loss: 0.6835998892784119\n",
            "Epoch 147, Loss: 0.6692231893539429\n",
            "Epoch 148, Loss: 0.6557013988494873\n",
            "Epoch 149, Loss: 0.6429922580718994\n",
            "Epoch 150, Loss: 0.6310495734214783\n",
            "Epoch 151, Loss: 0.6198291182518005\n",
            "Epoch 152, Loss: 0.6092901825904846\n",
            "Epoch 153, Loss: 0.5993891358375549\n",
            "Epoch 154, Loss: 0.5900885462760925\n",
            "Epoch 155, Loss: 0.5813484787940979\n",
            "Epoch 156, Loss: 0.5731322765350342\n",
            "Epoch 157, Loss: 0.5654057860374451\n",
            "Epoch 158, Loss: 0.5581343173980713\n",
            "Epoch 159, Loss: 0.551287829875946\n",
            "Epoch 160, Loss: 0.5448341369628906\n",
            "Epoch 161, Loss: 0.5387462377548218\n",
            "Epoch 162, Loss: 0.5329939723014832\n",
            "Epoch 163, Loss: 0.527554452419281\n",
            "Epoch 164, Loss: 0.5224027037620544\n",
            "Epoch 165, Loss: 0.5175163745880127\n",
            "Epoch 166, Loss: 0.5128746032714844\n",
            "Epoch 167, Loss: 0.5084568858146667\n",
            "Epoch 168, Loss: 0.5042456984519958\n",
            "Epoch 169, Loss: 0.5002247095108032\n",
            "Epoch 170, Loss: 0.4963778555393219\n",
            "Epoch 171, Loss: 0.4926913380622864\n",
            "Epoch 172, Loss: 0.48915064334869385\n",
            "Epoch 173, Loss: 0.4857443869113922\n",
            "Epoch 174, Loss: 0.4824613332748413\n",
            "Epoch 175, Loss: 0.47929099202156067\n",
            "Epoch 176, Loss: 0.47622430324554443\n",
            "Epoch 177, Loss: 0.4732527434825897\n",
            "Epoch 178, Loss: 0.47036752104759216\n",
            "Epoch 179, Loss: 0.4675626754760742\n",
            "Epoch 180, Loss: 0.4648308753967285\n",
            "Epoch 181, Loss: 0.46216651797294617\n",
            "Epoch 182, Loss: 0.4595639109611511\n",
            "Epoch 183, Loss: 0.45701998472213745\n",
            "Epoch 184, Loss: 0.45452773571014404\n",
            "Epoch 185, Loss: 0.4520845115184784\n",
            "Epoch 186, Loss: 0.44968709349632263\n",
            "Epoch 187, Loss: 0.44733288884162903\n",
            "Epoch 188, Loss: 0.44501715898513794\n",
            "Epoch 189, Loss: 0.4427383244037628\n",
            "Epoch 190, Loss: 0.440495103597641\n",
            "Epoch 191, Loss: 0.4382835626602173\n",
            "Epoch 192, Loss: 0.43610304594039917\n",
            "Epoch 193, Loss: 0.4339514672756195\n",
            "Epoch 194, Loss: 0.4318283200263977\n",
            "Epoch 195, Loss: 0.42973148822784424\n",
            "Epoch 196, Loss: 0.4276596009731293\n",
            "Epoch 197, Loss: 0.4256121814250946\n",
            "Epoch 198, Loss: 0.42358800768852234\n",
            "Epoch 199, Loss: 0.4215862452983856\n",
            "Epoch 200, Loss: 0.4196065664291382\n",
            "Epoch 201, Loss: 0.4176481366157532\n",
            "Epoch 202, Loss: 0.41570958495140076\n",
            "Epoch 203, Loss: 0.41379231214523315\n",
            "Epoch 204, Loss: 0.4118940532207489\n",
            "Epoch 205, Loss: 0.4100147485733032\n",
            "Epoch 206, Loss: 0.4081544876098633\n",
            "Epoch 207, Loss: 0.40631285309791565\n",
            "Epoch 208, Loss: 0.40448901057243347\n",
            "Epoch 209, Loss: 0.40268248319625854\n",
            "Epoch 210, Loss: 0.4008937180042267\n",
            "Epoch 211, Loss: 0.399122029542923\n",
            "Epoch 212, Loss: 0.3973672091960907\n",
            "Epoch 213, Loss: 0.39562875032424927\n",
            "Epoch 214, Loss: 0.39390650391578674\n",
            "Epoch 215, Loss: 0.3922004699707031\n",
            "Epoch 216, Loss: 0.39050963521003723\n",
            "Epoch 217, Loss: 0.3888343572616577\n",
            "Epoch 218, Loss: 0.38717415928840637\n",
            "Epoch 219, Loss: 0.38552922010421753\n",
            "Epoch 220, Loss: 0.3838993310928345\n",
            "Epoch 221, Loss: 0.38228291273117065\n",
            "Epoch 222, Loss: 0.3806818723678589\n",
            "Epoch 223, Loss: 0.3790942132472992\n",
            "Epoch 224, Loss: 0.37752053141593933\n",
            "Epoch 225, Loss: 0.3759606182575226\n",
            "Epoch 226, Loss: 0.3744135797023773\n",
            "Epoch 227, Loss: 0.37288007140159607\n",
            "Epoch 228, Loss: 0.37135955691337585\n",
            "Epoch 229, Loss: 0.3698514997959137\n",
            "Epoch 230, Loss: 0.36835619807243347\n",
            "Epoch 231, Loss: 0.366873562335968\n",
            "Epoch 232, Loss: 0.36540278792381287\n",
            "Epoch 233, Loss: 0.36394405364990234\n",
            "Epoch 234, Loss: 0.36249735951423645\n",
            "Epoch 235, Loss: 0.36106234788894653\n",
            "Epoch 236, Loss: 0.3596396744251251\n",
            "Epoch 237, Loss: 0.35822737216949463\n",
            "Epoch 238, Loss: 0.3568263053894043\n",
            "Epoch 239, Loss: 0.3554370403289795\n",
            "Epoch 240, Loss: 0.3540584444999695\n",
            "Epoch 241, Loss: 0.35269078612327576\n",
            "Epoch 242, Loss: 0.35133370757102966\n",
            "Epoch 243, Loss: 0.3499872386455536\n",
            "Epoch 244, Loss: 0.34865111112594604\n",
            "Epoch 245, Loss: 0.3473249673843384\n",
            "Epoch 246, Loss: 0.3460098206996918\n",
            "Epoch 247, Loss: 0.34470507502555847\n",
            "Epoch 248, Loss: 0.3434094786643982\n",
            "Epoch 249, Loss: 0.3421241044998169\n",
            "Epoch 250, Loss: 0.34084874391555786\n",
            "Epoch 251, Loss: 0.33958253264427185\n",
            "Epoch 252, Loss: 0.33832594752311707\n",
            "Epoch 253, Loss: 0.3370797336101532\n",
            "Epoch 254, Loss: 0.33584240078926086\n",
            "Epoch 255, Loss: 0.3346141576766968\n",
            "Epoch 256, Loss: 0.3333956003189087\n",
            "Epoch 257, Loss: 0.3321862518787384\n",
            "Epoch 258, Loss: 0.33098626136779785\n",
            "Epoch 259, Loss: 0.3297942578792572\n",
            "Epoch 260, Loss: 0.3286114037036896\n",
            "Epoch 261, Loss: 0.3274378478527069\n",
            "Epoch 262, Loss: 0.3262733221054077\n",
            "Epoch 263, Loss: 0.325116902589798\n",
            "Epoch 264, Loss: 0.32396936416625977\n",
            "Epoch 265, Loss: 0.3228304982185364\n",
            "Epoch 266, Loss: 0.3216998875141144\n",
            "Epoch 267, Loss: 0.3205777108669281\n",
            "Epoch 268, Loss: 0.31946417689323425\n",
            "Epoch 269, Loss: 0.31835806369781494\n",
            "Epoch 270, Loss: 0.3172607123851776\n",
            "Epoch 271, Loss: 0.31617164611816406\n",
            "Epoch 272, Loss: 0.3150905668735504\n",
            "Epoch 273, Loss: 0.31401753425598145\n",
            "Epoch 274, Loss: 0.3129523992538452\n",
            "Epoch 275, Loss: 0.3118950128555298\n",
            "Epoch 276, Loss: 0.31084540486335754\n",
            "Epoch 277, Loss: 0.3098037838935852\n",
            "Epoch 278, Loss: 0.30876970291137695\n",
            "Epoch 279, Loss: 0.3077430725097656\n",
            "Epoch 280, Loss: 0.3067242503166199\n",
            "Epoch 281, Loss: 0.30571314692497253\n",
            "Epoch 282, Loss: 0.30470937490463257\n",
            "Epoch 283, Loss: 0.3037126958370209\n",
            "Epoch 284, Loss: 0.3027234375476837\n",
            "Epoch 285, Loss: 0.3017418682575226\n",
            "Epoch 286, Loss: 0.3007673919200897\n",
            "Epoch 287, Loss: 0.2997995615005493\n",
            "Epoch 288, Loss: 0.29883959889411926\n",
            "Epoch 289, Loss: 0.2978861629962921\n",
            "Epoch 290, Loss: 0.29693999886512756\n",
            "Epoch 291, Loss: 0.296000599861145\n",
            "Epoch 292, Loss: 0.29506826400756836\n",
            "Epoch 293, Loss: 0.2941425144672394\n",
            "Epoch 294, Loss: 0.2932240664958954\n",
            "Epoch 295, Loss: 0.29231199622154236\n",
            "Epoch 296, Loss: 0.2914063334465027\n",
            "Epoch 297, Loss: 0.2905079126358032\n",
            "Epoch 298, Loss: 0.2896161377429962\n",
            "Epoch 299, Loss: 0.28873005509376526\n",
            "Epoch 300, Loss: 0.2878514230251312\n",
            "Epoch 301, Loss: 0.28697872161865234\n",
            "Epoch 302, Loss: 0.28611257672309875\n",
            "Epoch 303, Loss: 0.2852526605129242\n",
            "Epoch 304, Loss: 0.2843991219997406\n",
            "Epoch 305, Loss: 0.2835520803928375\n",
            "Epoch 306, Loss: 0.2827107608318329\n",
            "Epoch 307, Loss: 0.2818760573863983\n",
            "Epoch 308, Loss: 0.2810473144054413\n",
            "Epoch 309, Loss: 0.28022444248199463\n",
            "Epoch 310, Loss: 0.2794080078601837\n",
            "Epoch 311, Loss: 0.278597354888916\n",
            "Epoch 312, Loss: 0.2777925133705139\n",
            "Epoch 313, Loss: 0.2769939601421356\n",
            "Epoch 314, Loss: 0.27620112895965576\n",
            "Epoch 315, Loss: 0.2754136025905609\n",
            "Epoch 316, Loss: 0.2746323347091675\n",
            "Epoch 317, Loss: 0.2738567292690277\n",
            "Epoch 318, Loss: 0.2730864882469177\n",
            "Epoch 319, Loss: 0.27232223749160767\n",
            "Epoch 320, Loss: 0.2715631425380707\n",
            "Epoch 321, Loss: 0.27080997824668884\n",
            "Epoch 322, Loss: 0.2700626254081726\n",
            "Epoch 323, Loss: 0.2693200707435608\n",
            "Epoch 324, Loss: 0.268583208322525\n",
            "Epoch 325, Loss: 0.26785197854042053\n",
            "Epoch 326, Loss: 0.2671261727809906\n",
            "Epoch 327, Loss: 0.2664050757884979\n",
            "Epoch 328, Loss: 0.26568925380706787\n",
            "Epoch 329, Loss: 0.26497939229011536\n",
            "Epoch 330, Loss: 0.2642742097377777\n",
            "Epoch 331, Loss: 0.263574481010437\n",
            "Epoch 332, Loss: 0.2628801167011261\n",
            "Epoch 333, Loss: 0.26218995451927185\n",
            "Epoch 334, Loss: 0.2615051567554474\n",
            "Epoch 335, Loss: 0.26082566380500793\n",
            "Epoch 336, Loss: 0.2601509988307953\n",
            "Epoch 337, Loss: 0.25948092341423035\n",
            "Epoch 338, Loss: 0.2588161826133728\n",
            "Epoch 339, Loss: 0.2581566572189331\n",
            "Epoch 340, Loss: 0.25750118494033813\n",
            "Epoch 341, Loss: 0.25685033202171326\n",
            "Epoch 342, Loss: 0.2562047839164734\n",
            "Epoch 343, Loss: 0.2555639445781708\n",
            "Epoch 344, Loss: 0.2549276649951935\n",
            "Epoch 345, Loss: 0.25429633259773254\n",
            "Epoch 346, Loss: 0.25366896390914917\n",
            "Epoch 347, Loss: 0.2530463933944702\n",
            "Epoch 348, Loss: 0.2524285614490509\n",
            "Epoch 349, Loss: 0.25181517004966736\n",
            "Epoch 350, Loss: 0.2512061297893524\n",
            "Epoch 351, Loss: 0.25060176849365234\n",
            "Epoch 352, Loss: 0.25000181794166565\n",
            "Epoch 353, Loss: 0.24940603971481323\n",
            "Epoch 354, Loss: 0.24881458282470703\n",
            "Epoch 355, Loss: 0.24822750687599182\n",
            "Epoch 356, Loss: 0.24764488637447357\n",
            "Epoch 357, Loss: 0.2470664083957672\n",
            "Epoch 358, Loss: 0.24649181962013245\n",
            "Epoch 359, Loss: 0.24592135846614838\n",
            "Epoch 360, Loss: 0.2453555166721344\n",
            "Epoch 361, Loss: 0.24479389190673828\n",
            "Epoch 362, Loss: 0.24423585832118988\n",
            "Epoch 363, Loss: 0.2436821460723877\n",
            "Epoch 364, Loss: 0.24313224852085114\n",
            "Epoch 365, Loss: 0.24258679151535034\n",
            "Epoch 366, Loss: 0.24204494059085846\n",
            "Epoch 367, Loss: 0.24150711297988892\n",
            "Epoch 368, Loss: 0.2409730851650238\n",
            "Epoch 369, Loss: 0.24044275283813477\n",
            "Epoch 370, Loss: 0.2399168610572815\n",
            "Epoch 371, Loss: 0.23939436674118042\n",
            "Epoch 372, Loss: 0.23887567222118378\n",
            "Epoch 373, Loss: 0.23836065828800201\n",
            "Epoch 374, Loss: 0.23784957826137543\n",
            "Epoch 375, Loss: 0.23734211921691895\n",
            "Epoch 376, Loss: 0.23683804273605347\n",
            "Epoch 377, Loss: 0.2363382875919342\n",
            "Epoch 378, Loss: 0.2358415722846985\n",
            "Epoch 379, Loss: 0.2353484183549881\n",
            "Epoch 380, Loss: 0.2348589450120926\n",
            "Epoch 381, Loss: 0.2343732863664627\n",
            "Epoch 382, Loss: 0.23389096558094025\n",
            "Epoch 383, Loss: 0.23341207206249237\n",
            "Epoch 384, Loss: 0.23293660581111908\n",
            "Epoch 385, Loss: 0.23246456682682037\n",
            "Epoch 386, Loss: 0.23199588060379028\n",
            "Epoch 387, Loss: 0.23153075575828552\n",
            "Epoch 388, Loss: 0.23106907308101654\n",
            "Epoch 389, Loss: 0.23061026632785797\n",
            "Epoch 390, Loss: 0.23015475273132324\n",
            "Epoch 391, Loss: 0.22970262169837952\n",
            "Epoch 392, Loss: 0.22925414144992828\n",
            "Epoch 393, Loss: 0.22880840301513672\n",
            "Epoch 394, Loss: 0.22836600244045258\n",
            "Epoch 395, Loss: 0.22792686522006989\n",
            "Epoch 396, Loss: 0.22749072313308716\n",
            "Epoch 397, Loss: 0.22705763578414917\n",
            "Epoch 398, Loss: 0.22662760317325592\n",
            "Epoch 399, Loss: 0.22620072960853577\n",
            "Epoch 400, Loss: 0.22577713429927826\n",
            "Epoch 401, Loss: 0.22535640001296997\n",
            "Epoch 402, Loss: 0.22493863105773926\n",
            "Epoch 403, Loss: 0.22452349960803986\n",
            "Epoch 404, Loss: 0.22411149740219116\n",
            "Epoch 405, Loss: 0.22370295226573944\n",
            "Epoch 406, Loss: 0.22329653799533844\n",
            "Epoch 407, Loss: 0.222893625497818\n",
            "Epoch 408, Loss: 0.222492977976799\n",
            "Epoch 409, Loss: 0.22209559381008148\n",
            "Epoch 410, Loss: 0.2217009961605072\n",
            "Epoch 411, Loss: 0.22130896151065826\n",
            "Epoch 412, Loss: 0.22091971337795258\n",
            "Epoch 413, Loss: 0.22053326666355133\n",
            "Epoch 414, Loss: 0.22014951705932617\n",
            "Epoch 415, Loss: 0.21976827085018158\n",
            "Epoch 416, Loss: 0.21939021348953247\n",
            "Epoch 417, Loss: 0.21901440620422363\n",
            "Epoch 418, Loss: 0.2186415046453476\n",
            "Epoch 419, Loss: 0.21827073395252228\n",
            "Epoch 420, Loss: 0.21790288388729095\n",
            "Epoch 421, Loss: 0.21753759682178497\n",
            "Epoch 422, Loss: 0.21717485785484314\n",
            "Epoch 423, Loss: 0.21681436896324158\n",
            "Epoch 424, Loss: 0.21645650267601013\n",
            "Epoch 425, Loss: 0.21610155701637268\n",
            "Epoch 426, Loss: 0.21574844419956207\n",
            "Epoch 427, Loss: 0.2153984010219574\n",
            "Epoch 428, Loss: 0.21505041420459747\n",
            "Epoch 429, Loss: 0.21470464766025543\n",
            "Epoch 430, Loss: 0.21436166763305664\n",
            "Epoch 431, Loss: 0.21402068436145782\n",
            "Epoch 432, Loss: 0.2136819213628769\n",
            "Epoch 433, Loss: 0.21334582567214966\n",
            "Epoch 434, Loss: 0.21301217377185822\n",
            "Epoch 435, Loss: 0.21268004179000854\n",
            "Epoch 436, Loss: 0.212350994348526\n",
            "Epoch 437, Loss: 0.2120237797498703\n",
            "Epoch 438, Loss: 0.2116987556219101\n",
            "Epoch 439, Loss: 0.21137644350528717\n",
            "Epoch 440, Loss: 0.2110554575920105\n",
            "Epoch 441, Loss: 0.2107371836900711\n",
            "Epoch 442, Loss: 0.21042117476463318\n",
            "Epoch 443, Loss: 0.21010710299015045\n",
            "Epoch 444, Loss: 0.2097950428724289\n",
            "Epoch 445, Loss: 0.20948514342308044\n",
            "Epoch 446, Loss: 0.2091774046421051\n",
            "Epoch 447, Loss: 0.20887123048305511\n",
            "Epoch 448, Loss: 0.20856791734695435\n",
            "Epoch 449, Loss: 0.2082662135362625\n",
            "Epoch 450, Loss: 0.20796655118465424\n",
            "Epoch 451, Loss: 0.20766882598400116\n",
            "Epoch 452, Loss: 0.2073729932308197\n",
            "Epoch 453, Loss: 0.2070797085762024\n",
            "Epoch 454, Loss: 0.2067873626947403\n",
            "Epoch 455, Loss: 0.2064974457025528\n",
            "Epoch 456, Loss: 0.20620961487293243\n",
            "Epoch 457, Loss: 0.20592337846755981\n",
            "Epoch 458, Loss: 0.2056393176317215\n",
            "Epoch 459, Loss: 0.20535649359226227\n",
            "Epoch 460, Loss: 0.20507611334323883\n",
            "Epoch 461, Loss: 0.20479737222194672\n",
            "Epoch 462, Loss: 0.20452044904232025\n",
            "Epoch 463, Loss: 0.20424515008926392\n",
            "Epoch 464, Loss: 0.20397168397903442\n",
            "Epoch 465, Loss: 0.20370016992092133\n",
            "Epoch 466, Loss: 0.20343026518821716\n",
            "Epoch 467, Loss: 0.20316201448440552\n",
            "Epoch 468, Loss: 0.20289568603038788\n",
            "Epoch 469, Loss: 0.20263080298900604\n",
            "Epoch 470, Loss: 0.20236791670322418\n",
            "Epoch 471, Loss: 0.20210625231266022\n",
            "Epoch 472, Loss: 0.20184645056724548\n",
            "Epoch 473, Loss: 0.20158815383911133\n",
            "Epoch 474, Loss: 0.20133152604103088\n",
            "Epoch 475, Loss: 0.20107680559158325\n",
            "Epoch 476, Loss: 0.20082330703735352\n",
            "Epoch 477, Loss: 0.20057183504104614\n",
            "Epoch 478, Loss: 0.20032158493995667\n",
            "Epoch 479, Loss: 0.2000727653503418\n",
            "Epoch 480, Loss: 0.19982551038265228\n",
            "Epoch 481, Loss: 0.19957990944385529\n",
            "Epoch 482, Loss: 0.1993357539176941\n",
            "Epoch 483, Loss: 0.1990930438041687\n",
            "Epoch 484, Loss: 0.19885192811489105\n",
            "Epoch 485, Loss: 0.19861239194869995\n",
            "Epoch 486, Loss: 0.1983742117881775\n",
            "Epoch 487, Loss: 0.19813746213912964\n",
            "Epoch 488, Loss: 0.19790197908878326\n",
            "Epoch 489, Loss: 0.19766809046268463\n",
            "Epoch 490, Loss: 0.1974356323480606\n",
            "Epoch 491, Loss: 0.1972043663263321\n",
            "Epoch 492, Loss: 0.1969742774963379\n",
            "Epoch 493, Loss: 0.19674600660800934\n",
            "Epoch 494, Loss: 0.19651880860328674\n",
            "Epoch 495, Loss: 0.19629307091236115\n",
            "Epoch 496, Loss: 0.19606854021549225\n",
            "Epoch 497, Loss: 0.19584542512893677\n",
            "Epoch 498, Loss: 0.19562369585037231\n",
            "Epoch 499, Loss: 0.1954030990600586\n",
            "Epoch 500, Loss: 0.19518376886844635\n",
            "Epoch 501, Loss: 0.1949656903743744\n",
            "Epoch 502, Loss: 0.19474881887435913\n",
            "Epoch 503, Loss: 0.1945333629846573\n",
            "Epoch 504, Loss: 0.194318950176239\n",
            "Epoch 505, Loss: 0.19410587847232819\n",
            "Epoch 506, Loss: 0.19389410316944122\n",
            "Epoch 507, Loss: 0.19368328154087067\n",
            "Epoch 508, Loss: 0.19347357749938965\n",
            "Epoch 509, Loss: 0.19326530396938324\n",
            "Epoch 510, Loss: 0.1930580586194992\n",
            "Epoch 511, Loss: 0.19285202026367188\n",
            "Epoch 512, Loss: 0.19264698028564453\n",
            "Epoch 513, Loss: 0.19244328141212463\n",
            "Epoch 514, Loss: 0.19224058091640472\n",
            "Epoch 515, Loss: 0.19203895330429077\n",
            "Epoch 516, Loss: 0.19183826446533203\n",
            "Epoch 517, Loss: 0.19163881242275238\n",
            "Epoch 518, Loss: 0.19144044816493988\n",
            "Epoch 519, Loss: 0.191243514418602\n",
            "Epoch 520, Loss: 0.1910470873117447\n",
            "Epoch 521, Loss: 0.19085177779197693\n",
            "Epoch 522, Loss: 0.1906576156616211\n",
            "Epoch 523, Loss: 0.19046448171138763\n",
            "Epoch 524, Loss: 0.19027218222618103\n",
            "Epoch 525, Loss: 0.19008110463619232\n",
            "Epoch 526, Loss: 0.1898907721042633\n",
            "Epoch 527, Loss: 0.18970155715942383\n",
            "Epoch 528, Loss: 0.18951316177845\n",
            "Epoch 529, Loss: 0.18932589888572693\n",
            "Epoch 530, Loss: 0.1891396939754486\n",
            "Epoch 531, Loss: 0.1889544427394867\n",
            "Epoch 532, Loss: 0.18876999616622925\n",
            "Epoch 533, Loss: 0.18858623504638672\n",
            "Epoch 534, Loss: 0.1884039044380188\n",
            "Epoch 535, Loss: 0.18822182714939117\n",
            "Epoch 536, Loss: 0.18804115056991577\n",
            "Epoch 537, Loss: 0.18786105513572693\n",
            "Epoch 538, Loss: 0.1876821368932724\n",
            "Epoch 539, Loss: 0.1875038743019104\n",
            "Epoch 540, Loss: 0.18732662498950958\n",
            "Epoch 541, Loss: 0.1871500015258789\n",
            "Epoch 542, Loss: 0.18697437644004822\n",
            "Epoch 543, Loss: 0.18679948151111603\n",
            "Epoch 544, Loss: 0.18662558495998383\n",
            "Epoch 545, Loss: 0.1864524781703949\n",
            "Epoch 546, Loss: 0.18628020584583282\n",
            "Epoch 547, Loss: 0.18610858917236328\n",
            "Epoch 548, Loss: 0.18593759834766388\n",
            "Epoch 549, Loss: 0.1857677549123764\n",
            "Epoch 550, Loss: 0.18559837341308594\n",
            "Epoch 551, Loss: 0.18542994558811188\n",
            "Epoch 552, Loss: 0.1852622926235199\n",
            "Epoch 553, Loss: 0.18509541451931\n",
            "Epoch 554, Loss: 0.1849292814731598\n",
            "Epoch 555, Loss: 0.18476352095603943\n",
            "Epoch 556, Loss: 0.18459878861904144\n",
            "Epoch 557, Loss: 0.1844349056482315\n",
            "Epoch 558, Loss: 0.18427161872386932\n",
            "Epoch 559, Loss: 0.18410912156105042\n",
            "Epoch 560, Loss: 0.18394693732261658\n",
            "Epoch 561, Loss: 0.18378566205501556\n",
            "Epoch 562, Loss: 0.18362531065940857\n",
            "Epoch 563, Loss: 0.18346546590328217\n",
            "Epoch 564, Loss: 0.18330621719360352\n",
            "Epoch 565, Loss: 0.18314772844314575\n",
            "Epoch 566, Loss: 0.18298977613449097\n",
            "Epoch 567, Loss: 0.18283267319202423\n",
            "Epoch 568, Loss: 0.18267592787742615\n",
            "Epoch 569, Loss: 0.1825200468301773\n",
            "Epoch 570, Loss: 0.18236485123634338\n",
            "Epoch 571, Loss: 0.1822100132703781\n",
            "Epoch 572, Loss: 0.1820557713508606\n",
            "Epoch 573, Loss: 0.18190227448940277\n",
            "Epoch 574, Loss: 0.181749626994133\n",
            "Epoch 575, Loss: 0.18159741163253784\n",
            "Epoch 576, Loss: 0.18144558370113373\n",
            "Epoch 577, Loss: 0.18129442632198334\n",
            "Epoch 578, Loss: 0.18114374577999115\n",
            "Epoch 579, Loss: 0.18099404871463776\n",
            "Epoch 580, Loss: 0.1808445006608963\n",
            "Epoch 581, Loss: 0.18069566786289215\n",
            "Epoch 582, Loss: 0.18054735660552979\n",
            "Epoch 583, Loss: 0.18039965629577637\n",
            "Epoch 584, Loss: 0.1802525371313095\n",
            "Epoch 585, Loss: 0.18010562658309937\n",
            "Epoch 586, Loss: 0.17995968461036682\n",
            "Epoch 587, Loss: 0.17981399595737457\n",
            "Epoch 588, Loss: 0.17966903746128082\n",
            "Epoch 589, Loss: 0.17952443659305573\n",
            "Epoch 590, Loss: 0.17938005924224854\n",
            "Epoch 591, Loss: 0.17923671007156372\n",
            "Epoch 592, Loss: 0.17909346520900726\n",
            "Epoch 593, Loss: 0.17895103991031647\n",
            "Epoch 594, Loss: 0.17880862951278687\n",
            "Epoch 595, Loss: 0.1786670833826065\n",
            "Epoch 596, Loss: 0.17852573096752167\n",
            "Epoch 597, Loss: 0.17838525772094727\n",
            "Epoch 598, Loss: 0.17824482917785645\n",
            "Epoch 599, Loss: 0.17810504138469696\n",
            "Epoch 600, Loss: 0.17796576023101807\n",
            "Epoch 601, Loss: 0.17782673239707947\n",
            "Epoch 602, Loss: 0.17768822610378265\n",
            "Epoch 603, Loss: 0.17755016684532166\n",
            "Epoch 604, Loss: 0.17741276323795319\n",
            "Epoch 605, Loss: 0.17727550864219666\n",
            "Epoch 606, Loss: 0.17713899910449982\n",
            "Epoch 607, Loss: 0.17700228095054626\n",
            "Epoch 608, Loss: 0.1768663376569748\n",
            "Epoch 609, Loss: 0.17673109471797943\n",
            "Epoch 610, Loss: 0.17659582197666168\n",
            "Epoch 611, Loss: 0.1764608770608902\n",
            "Epoch 612, Loss: 0.1763266772031784\n",
            "Epoch 613, Loss: 0.17619262635707855\n",
            "Epoch 614, Loss: 0.17605914175510406\n",
            "Epoch 615, Loss: 0.17592602968215942\n",
            "Epoch 616, Loss: 0.17579291760921478\n",
            "Epoch 617, Loss: 0.17566081881523132\n",
            "Epoch 618, Loss: 0.17552848160266876\n",
            "Epoch 619, Loss: 0.1753968596458435\n",
            "Epoch 620, Loss: 0.17526540160179138\n",
            "Epoch 621, Loss: 0.17513419687747955\n",
            "Epoch 622, Loss: 0.17500388622283936\n",
            "Epoch 623, Loss: 0.17487330734729767\n",
            "Epoch 624, Loss: 0.17474351823329926\n",
            "Epoch 625, Loss: 0.17461369931697845\n",
            "Epoch 626, Loss: 0.1744842231273651\n",
            "Epoch 627, Loss: 0.1743553727865219\n",
            "Epoch 628, Loss: 0.17422664165496826\n",
            "Epoch 629, Loss: 0.1740986555814743\n",
            "Epoch 630, Loss: 0.17397038638591766\n",
            "Epoch 631, Loss: 0.17384271323680878\n",
            "Epoch 632, Loss: 0.17371509969234467\n",
            "Epoch 633, Loss: 0.17358793318271637\n",
            "Epoch 634, Loss: 0.1734611839056015\n",
            "Epoch 635, Loss: 0.17333461344242096\n",
            "Epoch 636, Loss: 0.17320847511291504\n",
            "Epoch 637, Loss: 0.17308254539966583\n",
            "Epoch 638, Loss: 0.17295680940151215\n",
            "Epoch 639, Loss: 0.17283150553703308\n",
            "Epoch 640, Loss: 0.17270612716674805\n",
            "Epoch 641, Loss: 0.1725814938545227\n",
            "Epoch 642, Loss: 0.17245689034461975\n",
            "Epoch 643, Loss: 0.17233267426490784\n",
            "Epoch 644, Loss: 0.1722084879875183\n",
            "Epoch 645, Loss: 0.17208488285541534\n",
            "Epoch 646, Loss: 0.17196162045001984\n",
            "Epoch 647, Loss: 0.17183813452720642\n",
            "Epoch 648, Loss: 0.17171524465084076\n",
            "Epoch 649, Loss: 0.17159225046634674\n",
            "Epoch 650, Loss: 0.17146983742713928\n",
            "Epoch 651, Loss: 0.17134740948677063\n",
            "Epoch 652, Loss: 0.17122560739517212\n",
            "Epoch 653, Loss: 0.17110373079776764\n",
            "Epoch 654, Loss: 0.17098213732242584\n",
            "Epoch 655, Loss: 0.17086075246334076\n",
            "Epoch 656, Loss: 0.17073963582515717\n",
            "Epoch 657, Loss: 0.17061881721019745\n",
            "Epoch 658, Loss: 0.17049799859523773\n",
            "Epoch 659, Loss: 0.1703774631023407\n",
            "Epoch 660, Loss: 0.17025727033615112\n",
            "Epoch 661, Loss: 0.1701372265815735\n",
            "Epoch 662, Loss: 0.1700173020362854\n",
            "Epoch 663, Loss: 0.1698978990316391\n",
            "Epoch 664, Loss: 0.16977839171886444\n",
            "Epoch 665, Loss: 0.1696590930223465\n",
            "Epoch 666, Loss: 0.1695399433374405\n",
            "Epoch 667, Loss: 0.16942135989665985\n",
            "Epoch 668, Loss: 0.16930261254310608\n",
            "Epoch 669, Loss: 0.1691841036081314\n",
            "Epoch 670, Loss: 0.16906608641147614\n",
            "Epoch 671, Loss: 0.16894760727882385\n",
            "Epoch 672, Loss: 0.1688298135995865\n",
            "Epoch 673, Loss: 0.16871225833892822\n",
            "Epoch 674, Loss: 0.16859453916549683\n",
            "Epoch 675, Loss: 0.16847725212574005\n",
            "Epoch 676, Loss: 0.16835984587669373\n",
            "Epoch 677, Loss: 0.1682426482439041\n",
            "Epoch 678, Loss: 0.16812598705291748\n",
            "Epoch 679, Loss: 0.16800923645496368\n",
            "Epoch 680, Loss: 0.1678926944732666\n",
            "Epoch 681, Loss: 0.16777604818344116\n",
            "Epoch 682, Loss: 0.1676599383354187\n",
            "Epoch 683, Loss: 0.1675439178943634\n",
            "Epoch 684, Loss: 0.1674278825521469\n",
            "Epoch 685, Loss: 0.16731195151805878\n",
            "Epoch 686, Loss: 0.1671963632106781\n",
            "Epoch 687, Loss: 0.1670808643102646\n",
            "Epoch 688, Loss: 0.16696542501449585\n",
            "Epoch 689, Loss: 0.16685020923614502\n",
            "Epoch 690, Loss: 0.16673484444618225\n",
            "Epoch 691, Loss: 0.16662000119686127\n",
            "Epoch 692, Loss: 0.16650520265102386\n",
            "Epoch 693, Loss: 0.16639043390750885\n",
            "Epoch 694, Loss: 0.16627570986747742\n",
            "Epoch 695, Loss: 0.16616131365299225\n",
            "Epoch 696, Loss: 0.16604691743850708\n",
            "Epoch 697, Loss: 0.16593268513679504\n",
            "Epoch 698, Loss: 0.16581855714321136\n",
            "Epoch 699, Loss: 0.16570457816123962\n",
            "Epoch 700, Loss: 0.16559074819087982\n",
            "Epoch 701, Loss: 0.16547702252864838\n",
            "Epoch 702, Loss: 0.16536325216293335\n",
            "Epoch 703, Loss: 0.1652497500181198\n",
            "Epoch 704, Loss: 0.16513638198375702\n",
            "Epoch 705, Loss: 0.1650230884552002\n",
            "Epoch 706, Loss: 0.1649097353219986\n",
            "Epoch 707, Loss: 0.16479669511318207\n",
            "Epoch 708, Loss: 0.16468383371829987\n",
            "Epoch 709, Loss: 0.1645706593990326\n",
            "Epoch 710, Loss: 0.1644577533006668\n",
            "Epoch 711, Loss: 0.16434526443481445\n",
            "Epoch 712, Loss: 0.16423262655735016\n",
            "Epoch 713, Loss: 0.1641198843717575\n",
            "Epoch 714, Loss: 0.16400744020938873\n",
            "Epoch 715, Loss: 0.1638951301574707\n",
            "Epoch 716, Loss: 0.16378265619277954\n",
            "Epoch 717, Loss: 0.1636706292629242\n",
            "Epoch 718, Loss: 0.1635587364435196\n",
            "Epoch 719, Loss: 0.16344663500785828\n",
            "Epoch 720, Loss: 0.1633349508047104\n",
            "Epoch 721, Loss: 0.1632225066423416\n",
            "Epoch 722, Loss: 0.1631108671426773\n",
            "Epoch 723, Loss: 0.1629990041255951\n",
            "Epoch 724, Loss: 0.16288737952709198\n",
            "Epoch 725, Loss: 0.1627759337425232\n",
            "Epoch 726, Loss: 0.1626642346382141\n",
            "Epoch 727, Loss: 0.16255266964435577\n",
            "Epoch 728, Loss: 0.16244155168533325\n",
            "Epoch 729, Loss: 0.1623304784297943\n",
            "Epoch 730, Loss: 0.16221903264522552\n",
            "Epoch 731, Loss: 0.16210781037807465\n",
            "Epoch 732, Loss: 0.16199660301208496\n",
            "Epoch 733, Loss: 0.16188576817512512\n",
            "Epoch 734, Loss: 0.1617744117975235\n",
            "Epoch 735, Loss: 0.16166386008262634\n",
            "Epoch 736, Loss: 0.16155292093753815\n",
            "Epoch 737, Loss: 0.1614420861005783\n",
            "Epoch 738, Loss: 0.1613311916589737\n",
            "Epoch 739, Loss: 0.16122055053710938\n",
            "Epoch 740, Loss: 0.16110986471176147\n",
            "Epoch 741, Loss: 0.16099916398525238\n",
            "Epoch 742, Loss: 0.16088877618312836\n",
            "Epoch 743, Loss: 0.16077812016010284\n",
            "Epoch 744, Loss: 0.16066761314868927\n",
            "Epoch 745, Loss: 0.16055721044540405\n",
            "Epoch 746, Loss: 0.16044668853282928\n",
            "Epoch 747, Loss: 0.16033624112606049\n",
            "Epoch 748, Loss: 0.16022585332393646\n",
            "Epoch 749, Loss: 0.16011549532413483\n",
            "Epoch 750, Loss: 0.1600053906440735\n",
            "Epoch 751, Loss: 0.15989544987678528\n",
            "Epoch 752, Loss: 0.15978509187698364\n",
            "Epoch 753, Loss: 0.15967483818531036\n",
            "Epoch 754, Loss: 0.15956498682498932\n",
            "Epoch 755, Loss: 0.15945471823215485\n",
            "Epoch 756, Loss: 0.15934449434280396\n",
            "Epoch 757, Loss: 0.15923428535461426\n",
            "Epoch 758, Loss: 0.15912456810474396\n",
            "Epoch 759, Loss: 0.15901464223861694\n",
            "Epoch 760, Loss: 0.15890461206436157\n",
            "Epoch 761, Loss: 0.15879501402378082\n",
            "Epoch 762, Loss: 0.1586848795413971\n",
            "Epoch 763, Loss: 0.1585751473903656\n",
            "Epoch 764, Loss: 0.1584651619195938\n",
            "Epoch 765, Loss: 0.1583554744720459\n",
            "Epoch 766, Loss: 0.15824566781520844\n",
            "Epoch 767, Loss: 0.1581355482339859\n",
            "Epoch 768, Loss: 0.15802636742591858\n",
            "Epoch 769, Loss: 0.1579163670539856\n",
            "Epoch 770, Loss: 0.15780645608901978\n",
            "Epoch 771, Loss: 0.15769696235656738\n",
            "Epoch 772, Loss: 0.15758711099624634\n",
            "Epoch 773, Loss: 0.15747752785682678\n",
            "Epoch 774, Loss: 0.15736807882785797\n",
            "Epoch 775, Loss: 0.15725842118263245\n",
            "Epoch 776, Loss: 0.15714852511882782\n",
            "Epoch 777, Loss: 0.1570388674736023\n",
            "Epoch 778, Loss: 0.15692949295043945\n",
            "Epoch 779, Loss: 0.15681961178779602\n",
            "Epoch 780, Loss: 0.1567101627588272\n",
            "Epoch 781, Loss: 0.15660037100315094\n",
            "Epoch 782, Loss: 0.156490758061409\n",
            "Epoch 783, Loss: 0.15638117492198944\n",
            "Epoch 784, Loss: 0.1562718003988266\n",
            "Epoch 785, Loss: 0.1561623513698578\n",
            "Epoch 786, Loss: 0.15605252981185913\n",
            "Epoch 787, Loss: 0.15594308078289032\n",
            "Epoch 788, Loss: 0.15583348274230957\n",
            "Epoch 789, Loss: 0.15572400391101837\n",
            "Epoch 790, Loss: 0.15561443567276\n",
            "Epoch 791, Loss: 0.15550494194030762\n",
            "Epoch 792, Loss: 0.15539531409740448\n",
            "Epoch 793, Loss: 0.15528593957424164\n",
            "Epoch 794, Loss: 0.15517616271972656\n",
            "Epoch 795, Loss: 0.1550665944814682\n",
            "Epoch 796, Loss: 0.15495681762695312\n",
            "Epoch 797, Loss: 0.15484736859798431\n",
            "Epoch 798, Loss: 0.15473784506320953\n",
            "Epoch 799, Loss: 0.1546282321214676\n",
            "Epoch 800, Loss: 0.15451879799365997\n",
            "Epoch 801, Loss: 0.15440906584262848\n",
            "Epoch 802, Loss: 0.15429925918579102\n",
            "Epoch 803, Loss: 0.1541898399591446\n",
            "Epoch 804, Loss: 0.15408004820346832\n",
            "Epoch 805, Loss: 0.15397056937217712\n",
            "Epoch 806, Loss: 0.153860941529274\n",
            "Epoch 807, Loss: 0.15375113487243652\n",
            "Epoch 808, Loss: 0.15364132821559906\n",
            "Epoch 809, Loss: 0.15353168547153473\n",
            "Epoch 810, Loss: 0.15342213213443756\n",
            "Epoch 811, Loss: 0.15331244468688965\n",
            "Epoch 812, Loss: 0.15320266783237457\n",
            "Epoch 813, Loss: 0.15309301018714905\n",
            "Epoch 814, Loss: 0.1529833972454071\n",
            "Epoch 815, Loss: 0.15287351608276367\n",
            "Epoch 816, Loss: 0.15276369452476501\n",
            "Epoch 817, Loss: 0.152653768658638\n",
            "Epoch 818, Loss: 0.1525442749261856\n",
            "Epoch 819, Loss: 0.15243424475193024\n",
            "Epoch 820, Loss: 0.152324378490448\n",
            "Epoch 821, Loss: 0.15221446752548218\n",
            "Epoch 822, Loss: 0.15210486948490143\n",
            "Epoch 823, Loss: 0.15199483931064606\n",
            "Epoch 824, Loss: 0.15188492834568024\n",
            "Epoch 825, Loss: 0.1517745852470398\n",
            "Epoch 826, Loss: 0.15166495740413666\n",
            "Epoch 827, Loss: 0.1515546441078186\n",
            "Epoch 828, Loss: 0.15144483745098114\n",
            "Epoch 829, Loss: 0.15133486688137054\n",
            "Epoch 830, Loss: 0.15122464299201965\n",
            "Epoch 831, Loss: 0.15111485123634338\n",
            "Epoch 832, Loss: 0.15100465714931488\n",
            "Epoch 833, Loss: 0.15089452266693115\n",
            "Epoch 834, Loss: 0.1507844477891922\n",
            "Epoch 835, Loss: 0.15067410469055176\n",
            "Epoch 836, Loss: 0.15056408941745758\n",
            "Epoch 837, Loss: 0.15045365691184998\n",
            "Epoch 838, Loss: 0.15034343302249908\n",
            "Epoch 839, Loss: 0.1502332240343094\n",
            "Epoch 840, Loss: 0.1501229852437973\n",
            "Epoch 841, Loss: 0.15001247823238373\n",
            "Epoch 842, Loss: 0.14990225434303284\n",
            "Epoch 843, Loss: 0.14979194104671478\n",
            "Epoch 844, Loss: 0.1496811956167221\n",
            "Epoch 845, Loss: 0.14957088232040405\n",
            "Epoch 846, Loss: 0.14946044981479645\n",
            "Epoch 847, Loss: 0.14934977889060974\n",
            "Epoch 848, Loss: 0.1492394059896469\n",
            "Epoch 849, Loss: 0.14912885427474976\n",
            "Epoch 850, Loss: 0.149018332362175\n",
            "Epoch 851, Loss: 0.14890778064727783\n",
            "Epoch 852, Loss: 0.14879699051380157\n",
            "Epoch 853, Loss: 0.14868640899658203\n",
            "Epoch 854, Loss: 0.14857566356658936\n",
            "Epoch 855, Loss: 0.14846500754356384\n",
            "Epoch 856, Loss: 0.1483541876077652\n",
            "Epoch 857, Loss: 0.14824332296848297\n",
            "Epoch 858, Loss: 0.14813251793384552\n",
            "Epoch 859, Loss: 0.14802151918411255\n",
            "Epoch 860, Loss: 0.14791065454483032\n",
            "Epoch 861, Loss: 0.14779983460903168\n",
            "Epoch 862, Loss: 0.14768895506858826\n",
            "Epoch 863, Loss: 0.14757774770259857\n",
            "Epoch 864, Loss: 0.14746683835983276\n",
            "Epoch 865, Loss: 0.14735561609268188\n",
            "Epoch 866, Loss: 0.14724493026733398\n",
            "Epoch 867, Loss: 0.14713340997695923\n",
            "Epoch 868, Loss: 0.14702245593070984\n",
            "Epoch 869, Loss: 0.1469111442565918\n",
            "Epoch 870, Loss: 0.1467999815940857\n",
            "Epoch 871, Loss: 0.14668847620487213\n",
            "Epoch 872, Loss: 0.14657719433307648\n",
            "Epoch 873, Loss: 0.14646616578102112\n",
            "Epoch 874, Loss: 0.1463548094034195\n",
            "Epoch 875, Loss: 0.14624318480491638\n",
            "Epoch 876, Loss: 0.14613190293312073\n",
            "Epoch 877, Loss: 0.14602030813694\n",
            "Epoch 878, Loss: 0.14590869843959808\n",
            "Epoch 879, Loss: 0.14579707384109497\n",
            "Epoch 880, Loss: 0.14568568766117096\n",
            "Epoch 881, Loss: 0.14557410776615143\n",
            "Epoch 882, Loss: 0.145462304353714\n",
            "Epoch 883, Loss: 0.1453506052494049\n",
            "Epoch 884, Loss: 0.14523877203464508\n",
            "Epoch 885, Loss: 0.1451270431280136\n",
            "Epoch 886, Loss: 0.14501510560512543\n",
            "Epoch 887, Loss: 0.14490331709384918\n",
            "Epoch 888, Loss: 0.1447916179895401\n",
            "Epoch 889, Loss: 0.1446797251701355\n",
            "Epoch 890, Loss: 0.144567608833313\n",
            "Epoch 891, Loss: 0.1444554477930069\n",
            "Epoch 892, Loss: 0.14434349536895752\n",
            "Epoch 893, Loss: 0.1442314088344574\n",
            "Epoch 894, Loss: 0.14411932229995728\n",
            "Epoch 895, Loss: 0.14400722086429596\n",
            "Epoch 896, Loss: 0.14389503002166748\n",
            "Epoch 897, Loss: 0.14378267526626587\n",
            "Epoch 898, Loss: 0.14367036521434784\n",
            "Epoch 899, Loss: 0.1435580849647522\n",
            "Epoch 900, Loss: 0.14344583451747894\n",
            "Epoch 901, Loss: 0.1433335244655609\n",
            "Epoch 902, Loss: 0.14322084188461304\n",
            "Epoch 903, Loss: 0.1431083083152771\n",
            "Epoch 904, Loss: 0.14299596846103668\n",
            "Epoch 905, Loss: 0.14288339018821716\n",
            "Epoch 906, Loss: 0.14277096092700958\n",
            "Epoch 907, Loss: 0.14265821874141693\n",
            "Epoch 908, Loss: 0.14254553616046906\n",
            "Epoch 909, Loss: 0.1424330174922943\n",
            "Epoch 910, Loss: 0.14232026040554047\n",
            "Epoch 911, Loss: 0.14220765233039856\n",
            "Epoch 912, Loss: 0.1420944184064865\n",
            "Epoch 913, Loss: 0.14198154211044312\n",
            "Epoch 914, Loss: 0.14186877012252808\n",
            "Epoch 915, Loss: 0.14175572991371155\n",
            "Epoch 916, Loss: 0.14164277911186218\n",
            "Epoch 917, Loss: 0.14152981340885162\n",
            "Epoch 918, Loss: 0.1414167732000351\n",
            "Epoch 919, Loss: 0.14130361378192902\n",
            "Epoch 920, Loss: 0.141190305352211\n",
            "Epoch 921, Loss: 0.1410771608352661\n",
            "Epoch 922, Loss: 0.140964075922966\n",
            "Epoch 923, Loss: 0.14085091650485992\n",
            "Epoch 924, Loss: 0.14073756337165833\n",
            "Epoch 925, Loss: 0.14062389731407166\n",
            "Epoch 926, Loss: 0.14051052927970886\n",
            "Epoch 927, Loss: 0.14039720594882965\n",
            "Epoch 928, Loss: 0.14028379321098328\n",
            "Epoch 929, Loss: 0.14017035067081451\n",
            "Epoch 930, Loss: 0.14005669951438904\n",
            "Epoch 931, Loss: 0.13994310796260834\n",
            "Epoch 932, Loss: 0.13982965052127838\n",
            "Epoch 933, Loss: 0.13971585035324097\n",
            "Epoch 934, Loss: 0.13960227370262146\n",
            "Epoch 935, Loss: 0.13948841392993927\n",
            "Epoch 936, Loss: 0.13937464356422424\n",
            "Epoch 937, Loss: 0.13926087319850922\n",
            "Epoch 938, Loss: 0.13914689421653748\n",
            "Epoch 939, Loss: 0.13903309404850006\n",
            "Epoch 940, Loss: 0.13891912996768951\n",
            "Epoch 941, Loss: 0.13880515098571777\n",
            "Epoch 942, Loss: 0.138691246509552\n",
            "Epoch 943, Loss: 0.1385769546031952\n",
            "Epoch 944, Loss: 0.13846313953399658\n",
            "Epoch 945, Loss: 0.13834863901138306\n",
            "Epoch 946, Loss: 0.13823439180850983\n",
            "Epoch 947, Loss: 0.1381203681230545\n",
            "Epoch 948, Loss: 0.13800619542598724\n",
            "Epoch 949, Loss: 0.13789184391498566\n",
            "Epoch 950, Loss: 0.1377773880958557\n",
            "Epoch 951, Loss: 0.13766299188137054\n",
            "Epoch 952, Loss: 0.13754881918430328\n",
            "Epoch 953, Loss: 0.13743411004543304\n",
            "Epoch 954, Loss: 0.1373196691274643\n",
            "Epoch 955, Loss: 0.13720522820949554\n",
            "Epoch 956, Loss: 0.13709057867527008\n",
            "Epoch 957, Loss: 0.1369762420654297\n",
            "Epoch 958, Loss: 0.1368616670370102\n",
            "Epoch 959, Loss: 0.13674651086330414\n",
            "Epoch 960, Loss: 0.13663198053836823\n",
            "Epoch 961, Loss: 0.13651728630065918\n",
            "Epoch 962, Loss: 0.13640251755714417\n",
            "Epoch 963, Loss: 0.1362876296043396\n",
            "Epoch 964, Loss: 0.13617268204689026\n",
            "Epoch 965, Loss: 0.136058047413826\n",
            "Epoch 966, Loss: 0.1359429955482483\n",
            "Epoch 967, Loss: 0.13582798838615417\n",
            "Epoch 968, Loss: 0.13571292161941528\n",
            "Epoch 969, Loss: 0.13559794425964355\n",
            "Epoch 970, Loss: 0.13548292219638824\n",
            "Epoch 971, Loss: 0.13536767661571503\n",
            "Epoch 972, Loss: 0.13525272905826569\n",
            "Epoch 973, Loss: 0.13513725996017456\n",
            "Epoch 974, Loss: 0.13502205908298492\n",
            "Epoch 975, Loss: 0.13490697741508484\n",
            "Epoch 976, Loss: 0.13479143381118774\n",
            "Epoch 977, Loss: 0.13467632234096527\n",
            "Epoch 978, Loss: 0.134560689330101\n",
            "Epoch 979, Loss: 0.13444525003433228\n",
            "Epoch 980, Loss: 0.13433004915714264\n",
            "Epoch 981, Loss: 0.13421422243118286\n",
            "Epoch 982, Loss: 0.13409896194934845\n",
            "Epoch 983, Loss: 0.13398338854312897\n",
            "Epoch 984, Loss: 0.13386765122413635\n",
            "Epoch 985, Loss: 0.1337519735097885\n",
            "Epoch 986, Loss: 0.13363642990589142\n",
            "Epoch 987, Loss: 0.13352082669734955\n",
            "Epoch 988, Loss: 0.13340498507022858\n",
            "Epoch 989, Loss: 0.13328920304775238\n",
            "Epoch 990, Loss: 0.13317351043224335\n",
            "Epoch 991, Loss: 0.1330575793981552\n",
            "Epoch 992, Loss: 0.13294199109077454\n",
            "Epoch 993, Loss: 0.13282601535320282\n",
            "Epoch 994, Loss: 0.1327100396156311\n",
            "Epoch 995, Loss: 0.13259416818618774\n",
            "Epoch 996, Loss: 0.13247811794281006\n",
            "Epoch 997, Loss: 0.13236214220523834\n",
            "Epoch 998, Loss: 0.13224604725837708\n",
            "Epoch 999, Loss: 0.13212984800338745\n",
            "Epoch 1000, Loss: 0.1320139318704605\n",
            "Genetic Algorithm MLP MSE: 0.13189764320850372\n",
            "\n",
            "Comparison of MSE:\n",
            "Standard MLP MSE: 0.31134364008903503\n",
            "Genetic Algorithm MLP MSE: 0.13189764320850372\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\n",
            "Plotting results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plot displayed.\n"
          ]
        }
      ]
    }
  ]
}
